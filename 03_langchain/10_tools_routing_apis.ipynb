{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX007/agent-labs/blob/main/03_langchain/10_tools_routing_apis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b815ef73",
      "metadata": {
        "id": "b815ef73"
      },
      "source": [
        "# Tools and Routing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "6et8ZAPaH7VF"
      },
      "id": "6et8ZAPaH7VF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "dotenv_path = find_dotenv() or '/content/OPENAI_API_KEY.env' # read local .env file\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools"
      ],
      "metadata": {
        "id": "deOgd4rJIDTk"
      },
      "id": "deOgd4rJIDTk"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-core langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywPZpTV6Q_iu",
        "outputId": "4f6d781e-6ce6-4339-81cb-5c74f273f29c"
      },
      "id": "ywPZpTV6Q_iu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139c45e6-65a4-4fcb-a109-e5ba41a80835",
      "metadata": {
        "height": 30,
        "id": "139c45e6-65a4-4fcb-a109-e5ba41a80835"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a17f623-9342-46bd-a913-9ea6be32a7a9",
      "metadata": {
        "height": 81,
        "id": "8a17f623-9342-46bd-a913-9ea6be32a7a9"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Search for weather online\"\"\"\n",
        "    return \"42f\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lopEB_zzMkkF",
        "outputId": "478d9987-a3c8-4e81-8962-98a6b994fc5a"
      },
      "id": "lopEB_zzMkkF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='search', description='Search for weather online', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x7c6325d5c2c0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db510949-acb8-4f69-b6c9-242b84fdc63a",
      "metadata": {
        "height": 30,
        "id": "db510949-acb8-4f69-b6c9-242b84fdc63a",
        "outputId": "f3795e44-3c05-4dde-c2e3-d8d756bfc75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "search.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c12426-5e1a-4057-8ae5-6dfb6beace97",
      "metadata": {
        "height": 30,
        "id": "c4c12426-5e1a-4057-8ae5-6dfb6beace97",
        "outputId": "2c720933-6f46-4753-f971-881c5419c3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Search for weather online'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "search.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d1c4e6-8313-41a0-ae7a-61343699cb7c",
      "metadata": {
        "height": 30,
        "id": "22d1c4e6-8313-41a0-ae7a-61343699cb7c",
        "outputId": "7501e14d-4a87-4baf-fa6f-3e12efd8061d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'title': 'Query', 'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "search.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8765af16-17fc-4490-98ab-4e9dd59337cf",
      "metadata": {
        "height": 81,
        "id": "8765af16-17fc-4490-98ab-4e9dd59337cf"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"Thing to search for\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SearchInput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "YMM5cOhRNXvS",
        "outputId": "ad4e198a-e382-4f2a-8503-4a563231ab88"
      },
      "id": "YMM5cOhRNXvS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.SearchInput"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>SearchInput</b><br/>def __init__(self, /, **data: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>!!! abstract &quot;Usage Documentation&quot;\n",
              "    [Models](../concepts/models.md)\n",
              "\n",
              "A base class for creating Pydantic models.\n",
              "\n",
              "Attributes:\n",
              "    __class_vars__: The names of the class variables defined on the model.\n",
              "    __private_attributes__: Metadata about the private attributes of the model.\n",
              "    __signature__: The synthesized `__init__` [`Signature`][inspect.Signature] of the model.\n",
              "\n",
              "    __pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n",
              "    __pydantic_core_schema__: The core schema of the model.\n",
              "    __pydantic_custom_init__: Whether the model has a custom `__init__` function.\n",
              "    __pydantic_decorators__: Metadata containing the decorators defined on the model.\n",
              "        This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n",
              "    __pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n",
              "        __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n",
              "    __pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n",
              "    __pydantic_post_init__: The name of the post-init method for the model, if defined.\n",
              "    __pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n",
              "    __pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n",
              "    __pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n",
              "\n",
              "    __pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
              "    __pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
              "\n",
              "    __pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n",
              "        is set to `&#x27;allow&#x27;`.\n",
              "    __pydantic_fields_set__: The names of fields explicitly set during instantiation.\n",
              "    __pydantic_private__: Values of private attributes set on the model instance.</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d20261-e18f-4989-808c-c4f36643d024",
      "metadata": {
        "height": 81,
        "id": "91d20261-e18f-4989-808c-c4f36643d024"
      },
      "outputs": [],
      "source": [
        "@tool(args_schema=SearchInput)\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Search for the weather online.\"\"\"\n",
        "    return \"42f\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4flvMiIAM5OS",
        "outputId": "66f14986-6ed9-4ca9-db18-189b0c1dff0f"
      },
      "id": "4flvMiIAM5OS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='search', description='Search for the weather online.', args_schema=<class '__main__.SearchInput'>, func=<function search at 0x7c6325d9cf40>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b3f7d0-a856-4842-82da-6c00df53e9d9",
      "metadata": {
        "height": 30,
        "id": "88b3f7d0-a856-4842-82da-6c00df53e9d9",
        "outputId": "a8a9b0c9-c6a6-4c96-9084-d93debc1896f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'description': 'Thing to search for',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "search.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060dc15b-f95f-47ab-b081-d6736f277ebc",
      "metadata": {
        "height": 30,
        "id": "060dc15b-f95f-47ab-b081-d6736f277ebc",
        "outputId": "dec1f680-dca5-4bdd-80de-60d9de785dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'42f'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "search.run(\"sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool 1: Get the Weather from Meteo"
      ],
      "metadata": {
        "id": "vzbjDpilRjC-"
      },
      "id": "vzbjDpilRjC-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93b85b2-1786-4f63-8e65-cd6a8b5c0b33",
      "metadata": {
        "height": 691,
        "id": "e93b85b2-1786-4f63-8e65-cd6a8b5c0b33"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import datetime\n",
        "\n",
        "# Define the input schema\n",
        "class OpenMeteoInput(BaseModel):\n",
        "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
        "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
        "\n",
        "@tool(args_schema=OpenMeteoInput)\n",
        "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
        "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
        "\n",
        "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'hourly': 'temperature_2m',\n",
        "        'forecast_days': 1,\n",
        "    }\n",
        "\n",
        "    # Make the request\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "    else:\n",
        "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
        "\n",
        "    current_utc_time = datetime.datetime.utcnow()\n",
        "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
        "    temperature_list = results['hourly']['temperature_2m']\n",
        "\n",
        "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
        "    current_temperature = temperature_list[closest_time_index]\n",
        "\n",
        "    return f'The current temperature is {current_temperature}°C'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_current_temperature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nw-4oQ6Og8V",
        "outputId": "b0a85fcd-6d50-4b78-eb16-e4e554641b57"
      },
      "id": "-Nw-4oQ6Og8V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='get_current_temperature', description='Fetch current temperature for given coordinates.', args_schema=<class '__main__.OpenMeteoInput'>, func=<function get_current_temperature at 0x7c6325d5cc20>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731ed353-a27d-42df-89a8-9767bafb23be",
      "metadata": {
        "height": 30,
        "id": "731ed353-a27d-42df-89a8-9767bafb23be",
        "outputId": "d2f1021d-8f9a-42c9-d771-ec7cb3947281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_current_temperature'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "get_current_temperature.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f62eb8-c528-4e4a-b078-22e9d9b20a09",
      "metadata": {
        "height": 30,
        "id": "d4f62eb8-c528-4e4a-b078-22e9d9b20a09",
        "outputId": "8c027437-40d1-4a17-8283-847c4c14db5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fetch current temperature for given coordinates.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "get_current_temperature.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ebb59f-cf0f-4281-99c3-87c8cfd3377b",
      "metadata": {
        "height": 30,
        "id": "38ebb59f-cf0f-4281-99c3-87c8cfd3377b",
        "outputId": "500b0487-32ba-4e7a-842c-1965bd69d3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
              "  'title': 'Latitude',\n",
              "  'type': 'number'},\n",
              " 'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
              "  'title': 'Longitude',\n",
              "  'type': 'number'}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "get_current_temperature.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36aacbec-9cdd-414a-b502-168cea350a30",
      "metadata": {
        "height": 45,
        "id": "36aacbec-9cdd-414a-b502-168cea350a30"
      },
      "outputs": [],
      "source": [
        "from langchain_core.utils.function_calling import convert_to_openai_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6277b6a8-f197-4057-a96a-5ebb61e18520",
      "metadata": {
        "height": 30,
        "id": "6277b6a8-f197-4057-a96a-5ebb61e18520",
        "outputId": "f7319ab2-134a-44f4-c988-e68d734ca533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'get_current_temperature',\n",
              " 'description': 'Fetch current temperature for given coordinates.',\n",
              " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
              "    'type': 'number'},\n",
              "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
              "    'type': 'number'}},\n",
              "  'required': ['latitude', 'longitude'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# convert it to openai function format\n",
        "convert_to_openai_function(get_current_temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e088eceb-424b-4da6-981f-63322c9ac56a",
      "metadata": {
        "height": 30,
        "id": "e088eceb-424b-4da6-981f-63322c9ac56a",
        "outputId": "ee162dcf-d050-48f8-8fab-9632d4152ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is 22.6°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# try the tool\n",
        "get_current_temperature.invoke({\"latitude\": 13, \"longitude\": 14})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool 2: Wikipedia Search"
      ],
      "metadata": {
        "id": "9F6jhS5dRcmy"
      },
      "id": "9F6jhS5dRcmy"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhy1zT3GPiuU",
        "outputId": "d832634b-3b68-4e96-8417-44118c122060"
      },
      "id": "Xhy1zT3GPiuU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eefc272-d205-4bad-ab00-282ccb3cc2fe",
      "metadata": {
        "height": 334,
        "id": "5eefc272-d205-4bad-ab00-282ccb3cc2fe"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
        "    page_titles = wikipedia.search(query)\n",
        "    summaries = []\n",
        "    for page_title in page_titles[: 3]:\n",
        "        try:\n",
        "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
        "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
        "        except (\n",
        "            self.wiki_client.exceptions.PageError,\n",
        "            self.wiki_client.exceptions.DisambiguationError,\n",
        "        ):\n",
        "            pass\n",
        "    if not summaries:\n",
        "        return \"No good Wikipedia Search Result was found\"\n",
        "    return \"\\n\\n\".join(summaries)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT0T6xRvPw6q",
        "outputId": "ba11dfc1-2174-4354-fdb0-04031584ff8e"
      },
      "id": "jT0T6xRvPw6q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='search_wikipedia', description='Run Wikipedia search and get page summaries.', args_schema=<class 'langchain_core.utils.pydantic.search_wikipedia'>, func=<function search_wikipedia at 0x7c6325d9eca0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289c5d0c-0e71-4d70-963f-9d9f58e53d56",
      "metadata": {
        "height": 30,
        "id": "289c5d0c-0e71-4d70-963f-9d9f58e53d56",
        "outputId": "26453f57-5256-4eb1-93bf-830a62c855d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'search_wikipedia'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "search_wikipedia.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69756d79-ec2f-4185-89af-d14de817fc27",
      "metadata": {
        "height": 30,
        "id": "69756d79-ec2f-4185-89af-d14de817fc27",
        "outputId": "2fd84046-9fe1-4bce-fce9-8fa82a367212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Run Wikipedia search and get page summaries.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "search_wikipedia.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b876cd-cc6c-484d-a3fa-d8810e22d564",
      "metadata": {
        "height": 30,
        "id": "d5b876cd-cc6c-484d-a3fa-d8810e22d564",
        "outputId": "ebcf396d-ce25-4252-85b6-a6248bcb5f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'search_wikipedia',\n",
              " 'description': 'Run Wikipedia search and get page summaries.',\n",
              " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
              "  'required': ['query'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# convert it to openai function format\n",
        "convert_to_openai_function(search_wikipedia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dfb10e9-5d1e-474a-9c8f-7abdf7939a34",
      "metadata": {
        "height": 30,
        "scrolled": true,
        "id": "6dfb10e9-5d1e-474a-9c8f-7abdf7939a34",
        "outputId": "bdf2f021-33a2-4bb9-9793-99e10087387a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1613030045.py:2: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  search_wikipedia({\"query\": \"langchain\"})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector\\'s position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\\nThese feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\\nVector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\\nVector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# try the tool\n",
        "search_wikipedia({\"query\": \"langchain\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto-generate Tools using OpenAPI specs"
      ],
      "metadata": {
        "id": "0mHuHKNkSvVL"
      },
      "id": "0mHuHKNkSvVL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Note**: OpenAPI auto-generation can have package compatibility issues in some environments (like Colab). For production agentic systems, manually defining tools often provides better control and reliability."
      ],
      "metadata": {
        "id": "dxN3hCmaX8dM"
      },
      "id": "dxN3hCmaX8dM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54cbe57e-f64c-4392-bcdd-9621fe1e46e5",
      "metadata": {
        "height": 62,
        "id": "54cbe57e-f64c-4392-bcdd-9621fe1e46e5"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
        "from langchain.utilities.openapi import OpenAPISpec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe38e50-874c-49bd-8681-f95dcab0b464",
      "metadata": {
        "height": 3105,
        "id": "7fe38e50-874c-49bd-8681-f95dcab0b464"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "{\n",
        "  \"openapi\": \"3.1.0\",\n",
        "  \"info\": {\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"title\": \"Swagger Petstore\",\n",
        "    \"license\": {\n",
        "      \"name\": \"MIT\"\n",
        "    }\n",
        "  },\n",
        "  \"servers\": [\n",
        "    {\n",
        "      \"url\": \"http://petstore.swagger.io/v1\"\n",
        "    }\n",
        "  ],\n",
        "  \"paths\": {\n",
        "    \"/pets\": {\n",
        "      \"get\": {\n",
        "        \"summary\": \"List all pets\",\n",
        "        \"operationId\": \"listPets\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"parameters\": [\n",
        "          {\n",
        "            \"name\": \"limit\",\n",
        "            \"in\": \"query\",\n",
        "            \"description\": \"How many items to return at one time (max 100)\",\n",
        "            \"required\": false,\n",
        "            \"schema\": {\n",
        "              \"type\": \"integer\",\n",
        "              \"maximum\": 100,\n",
        "              \"format\": \"int32\"\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"200\": {\n",
        "            \"description\": \"A paged array of pets\",\n",
        "            \"headers\": {\n",
        "              \"x-next\": {\n",
        "                \"description\": \"A link to the next page of responses\",\n",
        "                \"schema\": {\n",
        "                  \"type\": \"string\"\n",
        "                }\n",
        "              }\n",
        "            },\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Pets\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"post\": {\n",
        "        \"summary\": \"Create a pet\",\n",
        "        \"operationId\": \"createPets\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"201\": {\n",
        "            \"description\": \"Null response\"\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"/pets/{petId}\": {\n",
        "      \"get\": {\n",
        "        \"summary\": \"Info for a specific pet\",\n",
        "        \"operationId\": \"showPetById\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"parameters\": [\n",
        "          {\n",
        "            \"name\": \"petId\",\n",
        "            \"in\": \"path\",\n",
        "            \"required\": true,\n",
        "            \"description\": \"The id of the pet to retrieve\",\n",
        "            \"schema\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"200\": {\n",
        "            \"description\": \"Expected response to a valid request\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Pet\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"components\": {\n",
        "    \"schemas\": {\n",
        "      \"Pet\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"id\",\n",
        "          \"name\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"id\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int64\"\n",
        "          },\n",
        "          \"name\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"tag\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"Pets\": {\n",
        "        \"type\": \"array\",\n",
        "        \"maxItems\": 100,\n",
        "        \"items\": {\n",
        "          \"$ref\": \"#/components/schemas/Pet\"\n",
        "        }\n",
        "      },\n",
        "      \"Error\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"code\",\n",
        "          \"message\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"code\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int32\"\n",
        "          },\n",
        "          \"message\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "653156d4-d6a4-499b-aab3-cf4f7b1f0c47",
      "metadata": {
        "height": 30,
        "id": "653156d4-d6a4-499b-aab3-cf4f7b1f0c47"
      },
      "outputs": [],
      "source": [
        "spec = OpenAPISpec.from_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ba6100-3c88-4b05-af93-784b57bf7424",
      "metadata": {
        "height": 45,
        "id": "d9ba6100-3c88-4b05-af93-784b57bf7424"
      },
      "outputs": [],
      "source": [
        "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91199697-c662-438f-8c68-e6daa8aad07d",
      "metadata": {
        "height": 30,
        "id": "91199697-c662-438f-8c68-e6daa8aad07d",
        "outputId": "572625ab-63df-49cb-db37-ba088c5a3595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'listPets',\n",
              "  'description': 'List all pets',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'params': {'type': 'object',\n",
              "     'properties': {'limit': {'type': 'integer',\n",
              "       'maximum': 100.0,\n",
              "       'schema_format': 'int32',\n",
              "       'description': 'How many items to return at one time (max 100)'}},\n",
              "     'required': []}}}},\n",
              " {'name': 'createPets',\n",
              "  'description': 'Create a pet',\n",
              "  'parameters': {'type': 'object', 'properties': {}}},\n",
              " {'name': 'showPetById',\n",
              "  'description': 'Info for a specific pet',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'path_params': {'type': 'object',\n",
              "     'properties': {'petId': {'type': 'string',\n",
              "       'description': 'The id of the pet to retrieve'}},\n",
              "     'required': ['petId']}}}}]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pet_openai_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae8b3c1b-7a30-4b1b-abfd-e56f90b1d166",
      "metadata": {
        "height": 30,
        "id": "ae8b3c1b-7a30-4b1b-abfd-e56f90b1d166"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed100888-f3d4-4739-bba5-f839033850a3",
      "metadata": {
        "height": 45,
        "id": "ed100888-f3d4-4739-bba5-f839033850a3"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4063cdea-627c-4cc1-a2b5-9b5b6dcf179e",
      "metadata": {
        "height": 30,
        "id": "4063cdea-627c-4cc1-a2b5-9b5b6dcf179e",
        "outputId": "08692cf1-33fb-4815-deb2-ef2f5e48da25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'listPets', 'arguments': '{\"params\":{\"limit\":3}}'}})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"what are three pets names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a1f5534-cf06-4baf-b710-f169ea7434ac",
      "metadata": {
        "height": 30,
        "id": "3a1f5534-cf06-4baf-b710-f169ea7434ac",
        "outputId": "be768d12-7212-4d92-edb0-5d2f7805e285"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'showPetById', 'arguments': '{\"path_params\":{\"petId\":\"42\"}}'}})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"tell me about pet with id 42\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "198b21dd-c9de-491d-9a0c-71ae56727689",
      "metadata": {
        "id": "198b21dd-c9de-491d-9a0c-71ae56727689"
      },
      "source": [
        "## Routing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will show an example of function calling deciding between two candidate functions.\n",
        "\n",
        "Given our tools above, let's format these as OpenAI functions and show this same behavior."
      ],
      "metadata": {
        "id": "ROwf8FeeIREU"
      },
      "id": "ROwf8FeeIREU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8137758c-c5d3-47df-9062-5e31d43657e7",
      "metadata": {
        "height": 115,
        "id": "8137758c-c5d3-47df-9062-5e31d43657e7"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    convert_to_openai_function(f) for f in [\n",
        "        search_wikipedia, get_current_temperature\n",
        "    ]\n",
        "]\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99120542-36bc-4ed1-aa9e-e2294e282c81",
      "metadata": {
        "height": 30,
        "id": "99120542-36bc-4ed1-aa9e-e2294e282c81",
        "outputId": "0dd18e24-2c30-4d8d-fad5-7a2d9a4209c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 105, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbeidYkxl0btyFvxPtYUURSCU4Var', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--6d1fef14-1a3e-41b5-b915-4339e2125bc0-0', usage_metadata={'input_tokens': 105, 'output_tokens': 25, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model.invoke(\"what is the weather in sf right now\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a20047d9-4b34-4e6c-9407-570af1559bc8",
      "metadata": {
        "height": 30,
        "id": "a20047d9-4b34-4e6c-9407-570af1559bc8",
        "outputId": "2e6d4908-f7cc-4639-cff2-f62bbf06e0ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 101, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cbej4sx7284mZ7BIaZkhRIKaE4Tnt', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--ca2b8b37-3899-4174-bd2e-bdc355e98f61-0', usage_metadata={'input_tokens': 101, 'output_tokens': 16, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model.invoke(\"what is langchain\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In both cases, notice that the model 'understood' which tool to use."
      ],
      "metadata": {
        "id": "-3nwCb5nZcWs"
      },
      "id": "-3nwCb5nZcWs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831a0506-1d5c-4bc3-b67f-24e201a4fa6d",
      "metadata": {
        "height": 115,
        "id": "831a0506-1d5c-4bc3-b67f-24e201a4fa6d"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "chain = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c32ccc-6691-4dd5-98dc-aabf02563ad5",
      "metadata": {
        "height": 45,
        "id": "d9c32ccc-6691-4dd5-98dc-aabf02563ad5",
        "outputId": "8b1e987d-2ebe-4590-eb54-b8c0fddc998d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 113, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cbekr9ftk7B12XUDdBgtHp3ilcnsC', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--2d595b64-5019-4286-b4c0-6f54175e83b4-0', usage_metadata={'input_tokens': 113, 'output_tokens': 25, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "921e808c-6618-4d2f-85df-1f3089497724",
      "metadata": {
        "height": 45,
        "id": "921e808c-6618-4d2f-85df-1f3089497724"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094baef1-4140-41f4-9111-ff9710826e6b",
      "metadata": {
        "height": 30,
        "id": "094baef1-4140-41f4-9111-ff9710826e6b"
      },
      "outputs": [],
      "source": [
        "# add an output parser to the chain\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f105e8e8-d418-4d4a-95eb-52636d4e890f",
      "metadata": {
        "height": 45,
        "id": "f105e8e8-d418-4d4a-95eb-52636d4e890f"
      },
      "outputs": [],
      "source": [
        "result = chain.invoke({\"input\": \"what is the weather in sf right now\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujYEhWaSZ9FW",
        "outputId": "6869a5e9-c106-478c-e943-2900451bcb89"
      },
      "id": "ujYEhWaSZ9FW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='get_current_temperature', tool_input={'latitude': 37.7749, 'longitude': -122.4194}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 113, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbelXBgkLD6KRwFTmLeVgqnySvfyt', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--4406f4f2-efce-4c82-b4d2-9c0dfad4a639-0', usage_metadata={'input_tokens': 113, 'output_tokens': 25, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409b26c0-a1e0-4225-ae2e-396c1f76bf0a",
      "metadata": {
        "height": 30,
        "id": "409b26c0-a1e0-4225-ae2e-396c1f76bf0a",
        "outputId": "734b6748-d319-4bd1-ffb2-4560eded740c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.agents.AgentActionMessageLog"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.agents.AgentActionMessageLog</b><br/>def __init__(tool: str, tool_input: Union[str, dict], log: str, **kwargs: Any)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py</a>Representation of an action to be executed by an agent.\n",
              "\n",
              "This is similar to AgentAction, but includes a message log consisting of\n",
              "chat messages. This is useful when working with ChatModels, and is used\n",
              "to reconstruct conversation history from the agent&#x27;s perspective.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 100);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdde008-4b11-4ab2-a01c-6ae394a7dccf",
      "metadata": {
        "height": 30,
        "id": "9cdde008-4b11-4ab2-a01c-6ae394a7dccf",
        "outputId": "0620eca8-f929-4e0f-eea7-6f61f355fb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_current_temperature'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "result.tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ffb308-3d77-4acb-b4b5-e2b0d38f3860",
      "metadata": {
        "height": 30,
        "id": "66ffb308-3d77-4acb-b4b5-e2b0d38f3860",
        "outputId": "008f7a09-122a-4d32-a0e0-b7c5311355c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'latitude': 37.7749, 'longitude': -122.4194}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "result.tool_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e661b1-6d0d-43b9-9de4-19c6cceff291",
      "metadata": {
        "height": 30,
        "id": "07e661b1-6d0d-43b9-9de4-19c6cceff291",
        "outputId": "fc01f761-d6e4-4076-e332-bce5db1e334e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is 13.7°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# use retrieved arags as inputs to the tool to get the final answer (predefined print inside the function)\n",
        "get_current_temperature(result.tool_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "057e3072-a203-4a5e-b1f6-b250cd7bd33b",
      "metadata": {
        "height": 30,
        "id": "057e3072-a203-4a5e-b1f6-b250cd7bd33b"
      },
      "outputs": [],
      "source": [
        "# try an irrelevant prompt\n",
        "result = chain.invoke({\"input\": \"hi!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5be6bc0f-5b81-49fa-ac16-b8896847d87a",
      "metadata": {
        "height": 30,
        "id": "5be6bc0f-5b81-49fa-ac16-b8896847d87a",
        "outputId": "da53f42d-9ded-4979-9b67-05ab67e93dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.agents.AgentFinish"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.agents.AgentFinish</b><br/>def __init__(return_values: dict, log: str, **kwargs: Any)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py</a>Final return value of an ActionAgent.\n",
              "\n",
              "Agents return an AgentFinish when they have reached a stopping condition.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 136);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd128d20-f552-4cc5-a45e-f47b58c9982b",
      "metadata": {
        "height": 30,
        "id": "dd128d20-f552-4cc5-a45e-f47b58c9982b",
        "outputId": "984a92f5-ff21-4fab-910f-4c227928cb41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output': 'Well, hello there! How can I assist you today?'}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "result.return_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134f422a-b72b-40df-9552-cf9f9fc2d780",
      "metadata": {
        "height": 198,
        "id": "134f422a-b72b-40df-9552-cf9f9fc2d780"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.agent import AgentFinish\n",
        "def route(result):\n",
        "    if isinstance(result, AgentFinish):\n",
        "        return result.return_values['output']\n",
        "    else:\n",
        "        tools = {\n",
        "            \"search_wikipedia\": search_wikipedia,\n",
        "            \"get_current_temperature\": get_current_temperature,\n",
        "        }\n",
        "        return tools[result.tool].run(result.tool_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fefc329-b270-4ebb-b884-430e4e541e7f",
      "metadata": {
        "height": 45,
        "id": "8fefc329-b270-4ebb-b884-430e4e541e7f"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2dcb4b2-0e0d-425b-bff8-db7cd33afa16",
      "metadata": {
        "height": 45,
        "id": "b2dcb4b2-0e0d-425b-bff8-db7cd33afa16"
      },
      "outputs": [],
      "source": [
        "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "498d487b-ceba-4e9f-8a24-0f8c27438a18",
      "metadata": {
        "height": 30,
        "id": "498d487b-ceba-4e9f-8a24-0f8c27438a18",
        "outputId": "7a9543fa-78c0-4fc5-c305-1441b71b3789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is 13.7°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c93eb1b-044f-4c52-bcd4-dcd0e01f42e8",
      "metadata": {
        "height": 30,
        "id": "6c93eb1b-044f-4c52-bcd4-dcd0e01f42e8"
      },
      "outputs": [],
      "source": [
        "result = chain.invoke({\"input\": \"What is langchain?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0de3e7-2367-4cef-b3dd-efa69b701061",
      "metadata": {
        "height": 30,
        "scrolled": true,
        "id": "5c0de3e7-2367-4cef-b3dd-efa69b701061",
        "outputId": "f05535d6-9638-48aa-b39c-3e96259462e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector\\'s position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\\nThese feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\\nVector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\\nVector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a353363e-27b8-440f-a8b7-31bc2e861a42",
      "metadata": {
        "height": 30,
        "id": "a353363e-27b8-440f-a8b7-31bc2e861a42",
        "outputId": "feb6c7d1-4e47-4c03-a909-be4771a1f9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Well, hello there! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"hi!\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we explored how to manually define tools using both Pydantic models and the ```@tool``` decorator from ```langchain_core.tools```, and then convert these definitions into OpenAI-compatible function schemas. We also briefly introduced how tools can be auto-generated from OpenAPI specifications for larger or existing APIs. Finally, we saw how multiple functions can be combined, routed, and orchestrated inside a chain, allowing the model to choose the right tool and enabling more structured, agent-like workflows."
      ],
      "metadata": {
        "id": "6ASuo17hchve"
      },
      "id": "6ASuo17hchve"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1570d2-6215-4f24-802d-14e75db4319a",
      "metadata": {
        "height": 30,
        "id": "1e1570d2-6215-4f24-802d-14e75db4319a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}