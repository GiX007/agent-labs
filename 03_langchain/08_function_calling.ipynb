{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX007/agent-labs/blob/main/03_langchain/08_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16de7336",
      "metadata": {
        "id": "16de7336"
      },
      "source": [
        "# OpenAI Function Calling In LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "Qpoo5K6CtwRS"
      },
      "id": "Qpoo5K6CtwRS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "dotenv_path = find_dotenv() or '/content/OPENAI_API_KEY.env' # read local .env file\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1dddf9-8e44-4454-9d44-f8372cccf5ac",
      "metadata": {
        "height": 47,
        "id": "aa1dddf9-8e44-4454-9d44-f8372cccf5ac"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad68931a-f806-4ea9-969c-93b3902baf9b",
      "metadata": {
        "id": "ad68931a-f806-4ea9-969c-93b3902baf9b"
      },
      "source": [
        "## Pydantic Syntax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Pydantic data classes are a blend of Python's data classes with the validation power of Pydantic.\n",
        "\n",
        "They offer a concise way to define data structures while ensuring that the data adheres to specified types and constraints.\n",
        "\n",
        "This makes them ideal for reliably handling inputs and outputs in applications, especially when working with LLMs or APIs, as they catch errors early and simplify data serialization. They also integrate seamlessly with frameworks like LangChain, allowing structured data to flow safely through pipelines and tools.\n",
        "\n",
        "In standard python you would create a class like this:"
      ],
      "metadata": {
        "id": "Z5bBkTl32j19"
      },
      "id": "Z5bBkTl32j19"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1557226-36e2-484b-a2fb-bb7e3180342c",
      "metadata": {
        "height": 98,
        "id": "e1557226-36e2-484b-a2fb-bb7e3180342c"
      },
      "outputs": [],
      "source": [
        "class User:\n",
        "    def __init__(self, name: str, age: int, email: str):\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.email = email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b9b584-74dc-49b8-a7fe-3865368774e9",
      "metadata": {
        "height": 30,
        "id": "11b9b584-74dc-49b8-a7fe-3865368774e9"
      },
      "outputs": [],
      "source": [
        "foo = User(name=\"Joe\",age=32, email=\"joe@gmail.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6f9e9c-b83a-4859-8e65-e6488e05a071",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0f6f9e9c-b83a-4859-8e65-e6488e05a071",
        "outputId": "5bdfa819-15b2-4467-b603-f9909f834e9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Joe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "foo.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a6a0de-d7dc-414d-baaf-fa43c6d1f410",
      "metadata": {
        "height": 30,
        "id": "10a6a0de-d7dc-414d-baaf-fa43c6d1f410"
      },
      "outputs": [],
      "source": [
        "foo = User(name=\"Joe\",age=\"bar\", email=\"joe@gmail.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613b7b12-f061-44bc-989d-433cab609164",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "613b7b12-f061-44bc-989d-433cab609164",
        "outputId": "51995e8a-0fb7-464a-f050-3a10072f07d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bar'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "foo.age"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, if we use pydantic's BaseModel, we get:"
      ],
      "metadata": {
        "id": "XK2_aMKO3DDr"
      },
      "id": "XK2_aMKO3DDr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c541cb8d-fc55-4c94-a04f-a877cccf10ec",
      "metadata": {
        "height": 81,
        "id": "c541cb8d-fc55-4c94-a04f-a877cccf10ec"
      },
      "outputs": [],
      "source": [
        "class pUser(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    email: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27394d22-73e3-4918-9bdf-18cd7c973942",
      "metadata": {
        "height": 30,
        "id": "27394d22-73e3-4918-9bdf-18cd7c973942"
      },
      "outputs": [],
      "source": [
        "foo_p = pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f25241-ff47-454f-bac4-ba20ab937d70",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "49f25241-ff47-454f-bac4-ba20ab937d70",
        "outputId": "e0a5c1fd-f469-4aba-86a5-2b8f8b39dbde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Jane'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "foo_p.name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77405fab-9029-47e3-a6d3-f8338c2fefdc",
      "metadata": {
        "id": "77405fab-9029-47e3-a6d3-f8338c2fefdc"
      },
      "source": [
        "<p style=\\\"background-color:#F5C780; padding:15px\\\"><b>Note:</b> The next line is expected to fail.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37030df3-ec11-4523-ac66-b88f90099d1b",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "37030df3-ec11-4523-ac66-b88f90099d1b",
        "outputId": "09a4cbdd-d912-45d1-edf5-b826b9c2e494"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for pUser\nage\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bar', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3003212700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Jane\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jane@gmail.com\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for pUser\nage\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bar', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing"
          ]
        }
      ],
      "source": [
        "foo_p = pUser(name=\"Jane\", age=\"bar\", email=\"jane@gmail.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "911e7677-cc5d-4957-b6c3-b3ba1493de33",
      "metadata": {
        "height": 47,
        "id": "911e7677-cc5d-4957-b6c3-b3ba1493de33"
      },
      "outputs": [],
      "source": [
        "class Class(BaseModel):\n",
        "    students: List[pUser]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14920e50-688e-4dd4-9207-9b59c6b018c6",
      "metadata": {
        "height": 79,
        "id": "14920e50-688e-4dd4-9207-9b59c6b018c6"
      },
      "outputs": [],
      "source": [
        "obj = Class(\n",
        "    students=[pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cede1035-7581-4203-bab7-b8e6363c931f",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cede1035-7581-4203-bab7-b8e6363c931f",
        "outputId": "794de0ac-b22a-46b2-bd4a-ff5d9b2094cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class(students=[pUser(name='Jane', age=32, email='jane@gmail.com')])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "obj"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9c12cef-3a2d-46da-9c45-9a117e10f4a4",
      "metadata": {
        "id": "b9c12cef-3a2d-46da-9c45-9a117e10f4a4"
      },
      "source": [
        "## Pydantic to OpenAI function definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "617ceea9-009f-4325-adae-85ab29fccd68",
      "metadata": {
        "height": 79,
        "id": "617ceea9-009f-4325-adae-85ab29fccd68"
      },
      "outputs": [],
      "source": [
        "# Pydantic class\n",
        "class WeatherSearch(BaseModel):\n",
        "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
        "    airport_code: str = Field(description=\"airport code to get weather for\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22a438c-6692-47f9-9e00-1a95d04c6dd3",
      "metadata": {
        "height": 45,
        "id": "b22a438c-6692-47f9-9e00-1a95d04c6dd3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.utils.function_calling import convert_to_openai_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e152c4-8d04-4a02-b363-ee7691f60e31",
      "metadata": {
        "height": 45,
        "id": "97e152c4-8d04-4a02-b363-ee7691f60e31"
      },
      "outputs": [],
      "source": [
        "# Convert a Pydantic model into an OpenAI-compatible function schema for LLM function-calling (convert_to_openai_function = Pydantic → OpenAI function schema for LLMs)\n",
        "weather_function = convert_to_openai_function(WeatherSearch) # produces a JSON schema that OpenAI’s function-calling API can understand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36b041e-bd28-4e25-a0c1-fbeeeee4ae53",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f36b041e-bd28-4e25-a0c1-fbeeeee4ae53",
        "outputId": "8b913d74-0829-437c-f198-f1f7ac805703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'WeatherSearch',\n",
              " 'description': 'Call this with an airport code to get the weather at that airport',\n",
              " 'parameters': {'properties': {'airport_code': {'description': 'airport code to get weather for',\n",
              "    'type': 'string'}},\n",
              "  'required': ['airport_code'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "weather_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d7c573-2f84-441d-ab73-a3dd263318d4",
      "metadata": {
        "height": 62,
        "id": "c5d7c573-2f84-441d-ab73-a3dd263318d4"
      },
      "outputs": [],
      "source": [
        "class WeatherSearch1(BaseModel):\n",
        "    airport_code: str = Field(description=\"airport code to get weather for\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d99b688-a9a7-4446-977f-07918a5d93e1",
      "metadata": {
        "id": "3d99b688-a9a7-4446-977f-07918a5d93e1"
      },
      "source": [
        "Notice what happens in the next cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb08f095-8190-41c5-b49c-e3580cedf992",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb08f095-8190-41c5-b49c-e3580cedf992",
        "outputId": "9a175aa8-edec-405d-b898-c8ddfa0c7f8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'WeatherSearch1',\n",
              " 'description': '',\n",
              " 'parameters': {'properties': {'airport_code': {'description': 'airport code to get weather for',\n",
              "    'type': 'string'}},\n",
              "  'required': ['airport_code'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "convert_to_openai_function(WeatherSearch1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed22668a-e188-45a5-844e-deee62f9bf51",
      "metadata": {
        "height": 79,
        "id": "ed22668a-e188-45a5-844e-deee62f9bf51"
      },
      "outputs": [],
      "source": [
        "class WeatherSearch2(BaseModel):\n",
        "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
        "    airport_code: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e001e87-4338-4720-99b3-9dc4cb3e4faf",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e001e87-4338-4720-99b3-9dc4cb3e4faf",
        "outputId": "ff73b937-8fc4-4b63-ed42-9f8d5fd1ed85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'WeatherSearch2',\n",
              " 'description': 'Call this with an airport code to get the weather at that airport',\n",
              " 'parameters': {'properties': {'airport_code': {'type': 'string'}},\n",
              "  'required': ['airport_code'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "convert_to_openai_function(WeatherSearch2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl929vfZ5T8C",
        "outputId": "bdce0e9e-9620-484d-ea60-d84709d7d674"
      },
      "id": "cl929vfZ5T8C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.0.4)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35261e8-2d36-43a8-a051-a79bef35c8dd",
      "metadata": {
        "height": 30,
        "id": "a35261e8-2d36-43a8-a051-a79bef35c8dd"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bda0a6-9206-407a-b0da-966f9442a40c",
      "metadata": {
        "height": 30,
        "id": "93bda0a6-9206-407a-b0da-966f9442a40c"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe342d4-a7ef-49cd-b760-aa9a176d64d5",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afe342d4-a7ef-49cd-b760-aa9a176d64d5",
        "outputId": "cf452dab-d999-4ffd-a200-8a78e713aab9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 70, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPWsXy8eMYqYX0eEG3qj2EonECVV', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='lc_run--2b38bb40-ddb3-4c0e-b2de-34fa57791d39-0', usage_metadata={'input_tokens': 70, 'output_tokens': 17, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.invoke(\"what is the weather in SF today?\", functions=[weather_function])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511e12b6-bcfb-4862-b377-4251de9969ea",
      "metadata": {
        "height": 45,
        "id": "511e12b6-bcfb-4862-b377-4251de9969ea"
      },
      "outputs": [],
      "source": [
        "model_with_function = model.bind(functions=[weather_function])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de6241d9-667c-4b97-a50f-95c046fa640c",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de6241d9-667c-4b97-a50f-95c046fa640c",
        "outputId": "8a22829e-2b37-4359-db15-cedad15910fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 69, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPXdmkqY7iSaAPipNwAtwlCW8xd8', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='lc_run--9b02f5ea-8b88-4bff-a2e6-e0ea8ebfe91b-0', usage_metadata={'input_tokens': 69, 'output_tokens': 17, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model_with_function.invoke(\"what is the weather in sf?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the model returned `gpt-3.5-turbo` because that is the default underlying model used by `ChatOpenAI()` when no `model` parameter is explicitly specified. The output did not produce a direct answer because the LLM correctly decided to generate a `function_call` instead of normal text, identifying that the user's query should be handled by the `WeatherSearch` function. The `'output_tokens': 17` indicates that the model used 17 tokens to produce this function call response (we will see later how this affects the cost). Additionally, this implementation demonstrates an excellent use of `bind` (or passing functions to the model), as it allows the LLM to know about the function ahead of time without needing to provide it on every call, enabling automatic and structured function-calling behavior."
      ],
      "metadata": {
        "id": "BDuImUHD8K72"
      },
      "id": "BDuImUHD8K72"
    },
    {
      "cell_type": "markdown",
      "id": "ae78d6dd-bb38-4e55-9b65-0ef9005a52b9",
      "metadata": {
        "id": "ae78d6dd-bb38-4e55-9b65-0ef9005a52b9"
      },
      "source": [
        "## Forcing it to use a function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can force the model to use a function."
      ],
      "metadata": {
        "id": "3B_WokCP8kVu"
      },
      "id": "3B_WokCP8kVu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d2fbc0-df39-4e93-a22f-39a6285272b4",
      "metadata": {
        "height": 45,
        "id": "e7d2fbc0-df39-4e93-a22f-39a6285272b4"
      },
      "outputs": [],
      "source": [
        "model_with_forced_function = model.bind(functions=[weather_function], function_call={\"name\":\"WeatherSearch\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9f4063-9e15-41d7-9cf9-253548534176",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd9f4063-9e15-41d7-9cf9-253548534176",
        "outputId": "ecc5d16e-085b-49b6-d416-c28fb615d2d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 79, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPfsMjjWh7tGA3wKSWjnHtZNZ6zH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f3386b10-5a45-4552-89da-258fa9939824-0', usage_metadata={'input_tokens': 79, 'output_tokens': 7, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_with_forced_function.invoke(\"what is the weather in sf?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314ca7e6-b77c-4b9d-9c93-da6ef3c9c6f8",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "314ca7e6-b77c-4b9d-9c93-da6ef3c9c6f8",
        "outputId": "c6800510-bf56-48fd-8cb4-9af1b7b8a2c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"JFK\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 74, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPgFfyf1bGch8HWwGSOZ1r46EWqK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e5999670-0373-4a50-88a1-9c5e31f6bf58-0', usage_metadata={'input_tokens': 74, 'output_tokens': 7, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# the function will be used at any prompt\n",
        "model_with_forced_function.invoke(\"hi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ac391c3-cd81-4423-a33e-6583ec534850",
      "metadata": {
        "id": "5ac391c3-cd81-4423-a33e-6583ec534850"
      },
      "source": [
        "## Using in a chain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use this model bound to function in a chain as we normally would."
      ],
      "metadata": {
        "id": "M-c-lZpJ83av"
      },
      "id": "M-c-lZpJ83av"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12c86df-d628-4176-9f4e-24fb5a953a5d",
      "metadata": {
        "height": 30,
        "id": "c12c86df-d628-4176-9f4e-24fb5a953a5d"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f00dc6-5d22-44a5-a0a0-4fe1ab8167ac",
      "metadata": {
        "height": 81,
        "id": "83f00dc6-5d22-44a5-a0a0-4fe1ab8167ac"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eee3f5f-2176-4777-8c8a-2a197acc47a7",
      "metadata": {
        "height": 30,
        "id": "1eee3f5f-2176-4777-8c8a-2a197acc47a7"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model_with_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8587907e-b4c3-4acd-9e58-1137047d0fee",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8587907e-b4c3-4acd-9e58-1137047d0fee",
        "outputId": "75560003-0aaf-4054-e9a7-c761bbe1e8f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 75, 'total_tokens': 92, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPiKA8GxpF6dr8AUkzO8pFdQ1Sio', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='lc_run--79e6097a-0953-457b-82e2-7b30c1d5ceee-0', usage_metadata={'input_tokens': 75, 'output_tokens': 17, 'total_tokens': 92, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"what is the weather in sf?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f317408d-de5e-4774-993e-a8ac31a2f5fe",
      "metadata": {
        "id": "f317408d-de5e-4774-993e-a8ac31a2f5fe"
      },
      "source": [
        "## Using multiple functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even better, we can pass a set of functions and let the LLM decide which to use based on the question context."
      ],
      "metadata": {
        "id": "nlr8oOPV9Tgv"
      },
      "id": "nlr8oOPV9Tgv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c8e42e-f84e-4822-b1ee-a9955fa301c4",
      "metadata": {
        "height": 96,
        "id": "48c8e42e-f84e-4822-b1ee-a9955fa301c4"
      },
      "outputs": [],
      "source": [
        "class ArtistSearch(BaseModel):\n",
        "    \"\"\"Call this to get the names of songs by a particular artist\"\"\"\n",
        "    artist_name: str = Field(description=\"name of artist to look up\")\n",
        "    n: int = Field(description=\"number of results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a51599b-ee32-4f74-9925-b6264bf43242",
      "metadata": {
        "height": 81,
        "id": "9a51599b-ee32-4f74-9925-b6264bf43242"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    convert_to_openai_function(WeatherSearch),\n",
        "    convert_to_openai_function(ArtistSearch),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0cc9e3b-ba38-4eff-b285-d02ee5963725",
      "metadata": {
        "height": 30,
        "id": "e0cc9e3b-ba38-4eff-b285-d02ee5963725"
      },
      "outputs": [],
      "source": [
        "model_with_functions = model.bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01cd501-03b4-4207-b1be-0c33c12a0fa5",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01cd501-03b4-4207-b1be-0c33c12a0fa5",
        "outputId": "7f2d1418-f7d0-4e90-9152-c11d8f0c0a06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 116, 'total_tokens': 133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPji9ePRzAOHZVsvPLm8CsTZagvV', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='lc_run--176c1a13-c2c6-49cb-ae90-e8dad2bb2bde-0', usage_metadata={'input_tokens': 116, 'output_tokens': 17, 'total_tokens': 133, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# notice how the model understands which function to use\n",
        "model_with_functions.invoke(\"what is the weather in sf?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31599518-7387-4d08-9d68-8f5ba7282e8b",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31599518-7387-4d08-9d68-8f5ba7282e8b",
        "outputId": "2f342b05-946d-4a43-d81f-f1a4c5ab332d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"artist_name\":\"Taylor Swift\",\"n\":3}', 'name': 'ArtistSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 118, 'total_tokens': 139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPjsVlqzeDAxi2Q6mgWGRCOzSaxE', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='lc_run--bda971be-2a08-42d8-afbd-7d86595b12fa-0', usage_metadata={'input_tokens': 118, 'output_tokens': 21, 'total_tokens': 139, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# notice how the model understands which function to use\n",
        "model_with_functions.invoke(\"what are three songs by taylor swift?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6df989-6ea3-48af-b2c0-10978e0f4142",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e6df989-6ea3-48af-b2c0-10978e0f4142",
        "outputId": "175d6861-e92f-48d0-dbdf-a5337d042fc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 111, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbPjytXcqi4jRPalIf6bzlIXizBDL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--bd3340ec-2883-45fb-bef4-90eebf54879d-0', usage_metadata={'input_tokens': 111, 'output_tokens': 10, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# irrelevant input\n",
        "model_with_functions.invoke(\"hi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we explored how the Pydantic approach can simplify and structure our workflow. We learned how to define Pydantic classes and convert them into OpenAI-compatible functions, highlighting why this approach is more robust and reliable than using plain Python classes. We also saw different ways to call functions with LLMs, including using chains, `bind` to embed functions into the model, forcing specific function calls, and providing multiple functions while letting the LLM choose the most appropriate one. Overall, this demonstrates a clean, structured, and flexible way to integrate function-calling into AI applications."
      ],
      "metadata": {
        "id": "23joELYR-iOj"
      },
      "id": "23joELYR-iOj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29653b7-1382-4375-b681-10c51964fff5",
      "metadata": {
        "height": 30,
        "id": "b29653b7-1382-4375-b681-10c51964fff5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}