{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX007/agent-labs/blob/main/03_langchain/11_functional_conversation_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a3f6a4-8348-4cd6-a336-10ecb9cfaaa3",
      "metadata": {
        "id": "79a3f6a4-8348-4cd6-a336-10ecb9cfaaa3"
      },
      "source": [
        "# Conversational agent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "zLudcVzMc4ET"
      },
      "id": "zLudcVzMc4ET"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36261434-a96c-49e8-ad41-918d14da089a",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "36261434-a96c-49e8-ad41-918d14da089a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "dotenv_path = find_dotenv() or '/content/OPENAI_API_KEY.env' # read local .env file\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools"
      ],
      "metadata": {
        "id": "OD827vjBdLkq"
      },
      "id": "OD827vjBdLkq"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-core langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2gT30E2dPSD",
        "outputId": "efb5e4ab-707e-46ed-dae1-7c5165c36c34"
      },
      "id": "F2gT30E2dPSD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.35)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f44fbb-6708-4fce-bac4-55dc261e3a2d",
      "metadata": {
        "height": 30,
        "id": "20f44fbb-6708-4fce-bac4-55dc261e3a2d"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7406eb-334b-43d0-8110-31656a55b2fd",
      "metadata": {
        "height": 691,
        "id": "aa7406eb-334b-43d0-8110-31656a55b2fd"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "from datetime import datetime, UTC\n",
        "\n",
        "# Define the input schema\n",
        "class OpenMeteoInput(BaseModel):\n",
        "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
        "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
        "\n",
        "@tool(args_schema=OpenMeteoInput)\n",
        "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
        "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
        "\n",
        "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'hourly': 'temperature_2m',\n",
        "        'forecast_days': 1,\n",
        "    }\n",
        "\n",
        "    # Make the request\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "    else:\n",
        "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
        "\n",
        "    current_utc_time = datetime.now(UTC)\n",
        "    time_list = [\n",
        "        datetime.fromisoformat(time_str.replace(\"Z\", \"+00:00\")).astimezone(UTC)\n",
        "    for time_str in results['hourly']['time']\n",
        "     ]\n",
        "\n",
        "    temperature_list = results['hourly']['temperature_2m']\n",
        "\n",
        "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
        "    current_temperature = temperature_list[closest_time_index]\n",
        "\n",
        "    return f'The current temperature is {current_temperature}°C'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY-1vs5sdY_z",
        "outputId": "f00b95a1-7d7e-468d-b27b-ab8d55adaee2"
      },
      "id": "CY-1vs5sdY_z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ac0a1e7-567f-4775-a538-351a5ff099e8",
      "metadata": {
        "height": 351,
        "id": "3ac0a1e7-567f-4775-a538-351a5ff099e8"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
        "    page_titles = wikipedia.search(query)\n",
        "    summaries = []\n",
        "    for page_title in page_titles[: 3]:\n",
        "        try:\n",
        "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
        "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
        "        except (\n",
        "            self.wiki_client.exceptions.PageError,\n",
        "            self.wiki_client.exceptions.DisambiguationError,\n",
        "        ):\n",
        "            pass\n",
        "    if not summaries:\n",
        "        return \"No good Wikipedia Search Result was found\"\n",
        "    return \"\\n\\n\".join(summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4856d233-0916-4b97-8a7c-b494d5f2b8e0",
      "metadata": {
        "height": 30,
        "id": "4856d233-0916-4b97-8a7c-b494d5f2b8e0"
      },
      "outputs": [],
      "source": [
        "# all tools in a list\n",
        "tools = [get_current_temperature, search_wikipedia]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf0d789-559b-42df-9d6d-77a0cd8888d6",
      "metadata": {
        "height": 96,
        "id": "cdf0d789-559b-42df-9d6d-77a0cd8888d6"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933ce7cb-099c-4f43-a548-b355a5b66511",
      "metadata": {
        "height": 147,
        "id": "933ce7cb-099c-4f43-a548-b355a5b66511"
      },
      "outputs": [],
      "source": [
        "# Convert each @tool function into an OpenAI-compatible function schema\n",
        "functions = [convert_to_openai_function(f) for f in tools]\n",
        "\n",
        "# Bind these functions to the model so it can call them automatically\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
        "\n",
        "# Build a simple prompt template for system + user messages\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "\n",
        "# Create a chain: prompt → model (with tool-calls enabled) → parser for tool outputs\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4281a2d8-7884-40e0-b34d-09c39eecbb7a",
      "metadata": {
        "height": 45,
        "id": "4281a2d8-7884-40e0-b34d-09c39eecbb7a"
      },
      "outputs": [],
      "source": [
        "result = chain.invoke({\"input\": \"what is the weather is sf?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1dbc697-3e0a-4197-8ddc-2894763b4b85",
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b1dbc697-3e0a-4197-8ddc-2894763b4b85",
        "outputId": "dd8b09f9-c004-4364-a847-c3f8211ff29b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_current_temperature'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# result\n",
        "result.tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab829b59-803f-488f-bcf3-5119c224baa0",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab829b59-803f-488f-bcf3-5119c224baa0",
        "outputId": "f6ea058b-0d84-4fae-b8b7-6d7e42494b96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'latitude': 37.7749, 'longitude': -122.4194}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "result.tool_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52b4d483-c498-4932-a373-bc2f4da17c7f",
      "metadata": {
        "height": 115,
        "id": "52b4d483-c498-4932-a373-bc2f4da17c7f"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import MessagesPlaceholder\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```MessagesPlaceholder(\"agent_scratchpad\")``` creates an empty slot in the prompt where the agent can insert its intermediate reasoning, tool call traces, and previous steps. This placeholder is essential for multi-step agent workflows, because it lets the agent “remember” and feed its scratchpad back into each new LLM call."
      ],
      "metadata": {
        "id": "q9SCpyUJes-X"
      },
      "id": "q9SCpyUJes-X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ac6ea2-0e20-424a-ba33-6f8d627379b5",
      "metadata": {
        "height": 30,
        "id": "66ac6ea2-0e20-424a-ba33-6f8d627379b5"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bada1de8-d7c4-4880-98c2-d47cc65f684d",
      "metadata": {
        "height": 81,
        "id": "bada1de8-d7c4-4880-98c2-d47cc65f684d"
      },
      "outputs": [],
      "source": [
        "result1 = chain.invoke({\n",
        "    \"input\": \"what is the weather is sf?\",\n",
        "    \"agent_scratchpad\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp685gYfe9lw",
        "outputId": "7ed5225a-fa24-42ae-e692-d6924f7a941a"
      },
      "id": "bp685gYfe9lw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='get_current_temperature', tool_input={'latitude': 37.7749, 'longitude': -122.4194}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 112, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbfimuaHVcBCBHmHfgnUprhq5HKJh', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--873e2c53-063b-40ea-91a1-40c23612335c-0', usage_metadata={'input_tokens': 112, 'output_tokens': 25, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5f4e61-36a3-4d80-9c49-0b83cedb1592",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8d5f4e61-36a3-4d80-9c49-0b83cedb1592",
        "outputId": "a106f7c4-1806-411e-e38b-ccbb89b80663"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_current_temperature'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "result1.tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11845c11-7d41-455a-8ac0-4b8161acaf83",
      "metadata": {
        "height": 30,
        "id": "11845c11-7d41-455a-8ac0-4b8161acaf83"
      },
      "outputs": [],
      "source": [
        "# use tool_input args to get the weather\n",
        "observation = get_current_temperature.invoke(result1.tool_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810184c8-8495-4189-b83e-17220cf65bbe",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "810184c8-8495-4189-b83e-17220cf65bbe",
        "outputId": "aededcd6-0c83-42a1-f851-5ec9936056ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is 13.7°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1b223d-ea2a-414c-924c-512c4c9da66a",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "8c1b223d-ea2a-414c-924c-512c4c9da66a",
        "outputId": "822da856-89e4-45a9-b735-86e6e35b36fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.agents.AgentActionMessageLog"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.agents.AgentActionMessageLog</b><br/>def __init__(tool: str, tool_input: Union[str, dict], log: str, **kwargs: Any)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py</a>Representation of an action to be executed by an agent.\n",
              "\n",
              "This is similar to AgentAction, but includes a message log consisting of\n",
              "chat messages. This is useful when working with ChatModels, and is used\n",
              "to reconstruct conversation history from the agent&#x27;s perspective.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 100);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "type(result1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ca4278-165a-4915-8ec6-09e696f29d86",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ca4278-165a-4915-8ec6-09e696f29d86",
        "outputId": "8904afb6-7d17-4b4c-e7af-61b07934b27b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 112, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbfimuaHVcBCBHmHfgnUprhq5HKJh', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--873e2c53-063b-40ea-91a1-40c23612335c-0', usage_metadata={'input_tokens': 112, 'output_tokens': 25, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "result1.message_log"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously, we used ```convert_to_openai_function``` to turn a Pydantic model into an OpenAI function schema for defining tools. In contrast, ```format_to_openai_functions``` is used during agent execution to convert the agent's scratchpad (where the agent keeps track of its thoughts, previous steps, and tool calls while figuring out how to answer a question) or intermediate reasoning into a format compatible with OpenAI's function-calling protocol."
      ],
      "metadata": {
        "id": "rKG6gWtLis6T"
      },
      "id": "rKG6gWtLis6T"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.format_scratchpad import format_to_openai_functions"
      ],
      "metadata": {
        "id": "nxZdwlHaiRgz"
      },
      "id": "nxZdwlHaiRgz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e079a7-d58c-41c0-8762-4e183e72a1d1",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27e079a7-d58c-41c0-8762-4e183e72a1d1",
        "outputId": "34a11e14-cb65-49ec-da79-561f7b49a162"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 112, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbfimuaHVcBCBHmHfgnUprhq5HKJh', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--873e2c53-063b-40ea-91a1-40c23612335c-0', usage_metadata={'input_tokens': 112, 'output_tokens': 25, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " FunctionMessage(content='The current temperature is 13.7°C', additional_kwargs={}, response_metadata={}, name='get_current_temperature')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "format_to_openai_functions([(result1, observation), ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09735a9e-452d-472b-a4c0-35c315e9e53f",
      "metadata": {
        "height": 96,
        "id": "09735a9e-452d-472b-a4c0-35c315e9e53f"
      },
      "outputs": [],
      "source": [
        "result2 = chain.invoke({\n",
        "    \"input\": \"what is the weather is sf?\",\n",
        "    \"agent_scratchpad\": format_to_openai_functions([(result1, observation)])\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df61ecc-52fe-4fae-85a2-dbb61d68e2db",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9df61ecc-52fe-4fae-85a2-dbb61d68e2db",
        "outputId": "a1e12380-decc-4d39-9cd3-3bc1a571e622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 13.7°C.'}, log='The current temperature in San Francisco is 13.7°C.')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "result2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "QJNb1eGSl78M"
      },
      "id": "QJNb1eGSl78M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function runs an agent in a loop, feeding it the user input and its past reasoning (scratchpad), executing any tools the agent decides to call, collecting the results, and continuing until the agent signals it has finished."
      ],
      "metadata": {
        "id": "bPTVj4NfjZ8a"
      },
      "id": "bPTVj4NfjZ8a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9dd139f-e06a-4148-a025-ae100851c63e",
      "metadata": {
        "height": 300,
        "id": "d9dd139f-e06a-4148-a025-ae100851c63e"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.agent import AgentFinish\n",
        "def run_agent(user_input):\n",
        "    intermediate_steps = []\n",
        "    while True:\n",
        "        result = chain.invoke({\n",
        "            \"input\": user_input,\n",
        "            \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n",
        "        })\n",
        "        if isinstance(result, AgentFinish):\n",
        "            return result\n",
        "        tool = {\n",
        "            \"search_wikipedia\": search_wikipedia,\n",
        "            \"get_current_temperature\": get_current_temperature,\n",
        "        }[result.tool]\n",
        "        observation = tool.run(result.tool_input)\n",
        "        intermediate_steps.append((result, observation))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we create a new chain that first converts the agent's intermediate steps into the OpenAI function format (scratchpad) and then passes them along to the main chain for execution."
      ],
      "metadata": {
        "id": "X3zGPAPZjzUt"
      },
      "id": "X3zGPAPZjzUt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6c1121-70a6-41ae-8c3d-41f7cfc756af",
      "metadata": {
        "height": 96,
        "id": "4f6c1121-70a6-41ae-8c3d-41f7cfc756af"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "agent_chain = RunnablePassthrough.assign(\n",
        "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        ") | chain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quick Reminders:**\n",
        "\n",
        "There are 2 ways to create chains:\n",
        "  *   ```The prompt | model | ...``` syntax is a **quick, high-level way** to chain prompts, models, and parsers for simple or standard workflows.\n",
        "  *   ```Runnable``` objects (like ```RunnablePassthrough```) give us more control and flexibility, letting us manipulate inputs, outputs, and intermediate steps explicitly—useful for multi-step agents, custom scratchpads, or streaming pipelines.\n",
        "\n",
        "In this series of notebooks, we also use 2 ways of interacting with OpenAI models: one with the **client API** (where we used ```gpt-4o-mini```) and one with **ChatOpenAI** (commonly using ```gpt-3.5-turbo```)."
      ],
      "metadata": {
        "id": "O-rLi_XikdLq"
      },
      "id": "O-rLi_XikdLq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8bf88b6-9992-4041-8344-ef4921bf3cf2",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8bf88b6-9992-4041-8344-ef4921bf3cf2",
        "outputId": "ff35cd5c-6a4e-4048-fb5a-660d6bfe59f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 13.7°C.'}, log='The current temperature in San Francisco is 13.7°C.')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "run_agent(\"what is the weather is sf?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c94a493-b480-409a-968a-038c8895709c",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c94a493-b480-409a-968a-038c8895709c",
        "outputId": "e9a22485-86b9-443c-d8e2-e1bebc228acf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': 'A blockchain is a distributed ledger with growing lists of records (blocks) that are securely linked together via cryptographic hashes. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. Blockchains are managed by a peer-to-peer computer network for use as a public distributed ledger, where nodes collectively adhere to a consensus algorithm protocol to add and validate new transaction blocks. The concept of blockchain was introduced by Satoshi Nakamoto in 2008 as the public distributed ledger for bitcoin cryptocurrency transactions. Blockchains are resistant to alteration and are considered secure by design.'}, log='A blockchain is a distributed ledger with growing lists of records (blocks) that are securely linked together via cryptographic hashes. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. Blockchains are managed by a peer-to-peer computer network for use as a public distributed ledger, where nodes collectively adhere to a consensus algorithm protocol to add and validate new transaction blocks. The concept of blockchain was introduced by Satoshi Nakamoto in 2008 as the public distributed ledger for bitcoin cryptocurrency transactions. Blockchains are resistant to alteration and are considered secure by design.')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "run_agent(\"what is blockchain?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8c6fd7-7c8c-487a-81de-1dcff739a2f9",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8c6fd7-7c8c-487a-81de-1dcff739a2f9",
        "outputId": "6745d4ce-f025-4f5d-d358-22ab0bb69cfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': 'Well, hello there! How can I assist you today?'}, log='Well, hello there! How can I assist you today?')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "run_agent(\"hi!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b270a064-8cf1-44da-a59e-be622f9099b9",
      "metadata": {
        "height": 62,
        "id": "b270a064-8cf1-44da-a59e-be622f9099b9"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87baebf4-2555-4e98-aece-a1c327644817",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87baebf4-2555-4e98-aece-a1c327644817",
        "outputId": "cf1eed84-2b4a-418a-ce4f-87903b1e9081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `search_wikipedia` with `{'query': 'blockchain'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Blockchain\n",
            "Summary: A blockchain is a distributed ledger with growing lists of records (blocks) that are securely linked together via cryptographic hashes. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data (generally represented as a Merkle tree, where data nodes are represented by leaves). Since each block contains information about the previous block, they effectively form a chain (compare linked list data structure), with each additional block linking to the ones before it. Consequently, blockchain transactions are resistant to alteration because, once recorded, the data in any given block cannot be changed retroactively without altering all subsequent blocks and obtaining network consensus to accept these changes.\n",
            "Blockchains are typically managed by a peer-to-peer (P2P) computer network for use as a public distributed ledger, where nodes collectively adhere to a consensus algorithm protocol to add and validate new transaction blocks. Although blockchain records are not unalterable, since blockchain forks are possible, blockchains may be considered secure by design and exemplify a distributed computing system with high Byzantine fault tolerance.\n",
            "A blockchain was created by a person (or group of people) using the name (or pseudonym) Satoshi Nakamoto in 2008 to serve as the public distributed ledger for bitcoin cryptocurrency transactions, based on previous work by Stuart Haber, W. Scott Stornetta, and Dave Bayer. The implementation of the blockchain within bitcoin made it the first digital currency to solve the double-spending problem without the need for a trusted authority or central server. The bitcoin design has inspired other applications and blockchains that are readable by the public and are widely used by cryptocurrencies. The blockchain may be considered a type of payment rail.\n",
            "Private blockchains have been proposed for business use. Computerworld called the marketing of such privatized blockchains without a proper security model \"snake oil\"; however, others have argued that permissioned blockchains, if carefully designed, may be more decentralized and therefore more secure in practice than permissionless ones.\n",
            "\n",
            "\n",
            "\n",
            "Page: Solana (blockchain platform)\n",
            "Summary: Solana is a public blockchain platform that uses a proof-of-stake consensus mechanism and provides smart contract functionality. The platform's native cryptocurrency is SOL. Solana was founded in 2018 by Anatoly Yakovenko and Raj Gokal, and the network was launched in March 2020 by their San Francisco-based company, Solana Labs.\n",
            "Designed to support decentralized applications and high-throughput transactions, Solana gained traction as a competitor to Ethereum, particularly during the rise of non-fungible tokens (NFTs) in 2021. The platform's architecture aims to provide faster transaction speeds and lower costs than other major blockchains. However, the high volume of transactions has also contributed to several notable network outages that have impacted its stability and reliability.\n",
            "The history of Solana has been marked by rapid growth and volatility. After a successful funding round in June 2021, the price of SOL grew by nearly 12,000% that year, reaching a market capitalization of over $70 billion. The platform has since faced challenges, including a major wallet hack in August 2022, a price collapse following the bankruptcy of FTX, and legal scrutiny from the U.S. Securities and Exchange Commission, which in 2023 alleged that SOL qualifies as an unregistered security. Nevertheless, in January 2025 United States President Donald Trump's memecoin, $TRUMP, began using the Solana blockchain causing a brief surge to near all-time highs.\n",
            "\n",
            "\n",
            "\n",
            "Page: Polygon (blockchain)\n",
            "Summary: Polygon (formerly Matic Network) is a blockchain platform which aims to create a multi-chain blockchain system compatible with Ethereum. As with Ethereum, it uses a proof-of-stake consensus mechanism for processing transactions on-chain. Polygon's native token is POL, an ERC-20 token which allows for compatibility with other Ethereum cryptocurrencies. It is operated by Polygon Labs.\n",
            "Polygon is a natively Layer-2 network that uses Ethereum as a base network. In particular, transactions are first validated inside Polygon and then periodically committed in a \"checkpoint\": a Merkle root of transaction hashes is committed to Ethereum's mainnet by using \"Core contracts\".\n",
            "Polygon runs various decentralized applications (dApps) such as Defi, DAOs, and NFTs.\n",
            "\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mA blockchain is a distributed ledger with growing lists of records (blocks) that are securely linked together via cryptographic hashes. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. Blockchains are managed by a peer-to-peer computer network for use as a public distributed ledger, where nodes collectively adhere to a consensus algorithm protocol to add and validate new transaction blocks. The concept of blockchain was introduced by Satoshi Nakamoto in 2008 as the public distributed ledger for bitcoin cryptocurrency transactions. Blockchains are resistant to alteration and are considered secure by design. They have inspired various applications and are widely used in cryptocurrencies.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is blockchain?',\n",
              " 'output': 'A blockchain is a distributed ledger with growing lists of records (blocks) that are securely linked together via cryptographic hashes. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. Blockchains are managed by a peer-to-peer computer network for use as a public distributed ledger, where nodes collectively adhere to a consensus algorithm protocol to add and validate new transaction blocks. The concept of blockchain was introduced by Satoshi Nakamoto in 2008 as the public distributed ledger for bitcoin cryptocurrency transactions. Blockchains are resistant to alteration and are considered secure by design. They have inspired various applications and are widely used in cryptocurrencies.'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"what is blockchain?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2da813c-47c3-487e-8c43-444c9b4d9821",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2da813c-47c3-487e-8c43-444c9b4d9821",
        "outputId": "d20d354d-a361-47cb-e22c-2e10e227d348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'my name is bob',\n",
              " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"my name is bob\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ba8a9f-fcb2-44d0-878f-3017f607e955",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ba8a9f-fcb2-44d0-878f-3017f607e955",
        "outputId": "74dcecf2-155a-40a3-afb1-af1d0f17fbe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI'm sorry, I don't have access to your personal information. How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is my name',\n",
              " 'output': \"I'm sorry, I don't have access to your personal information. How can I assist you today?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"what is my name\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, the agent does not remember, let's fix this."
      ],
      "metadata": {
        "id": "kD5CHH1qo_8G"
      },
      "id": "kD5CHH1qo_8G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d1df28a-27da-4f8e-ab03-a37a276db74f",
      "metadata": {
        "height": 115,
        "id": "7d1df28a-27da-4f8e-ab03-a37a276db74f"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8598e87-de8a-4710-a90e-2a919adc00e2",
      "metadata": {
        "height": 79,
        "id": "a8598e87-de8a-4710-a90e-2a919adc00e2"
      },
      "outputs": [],
      "source": [
        "agent_chain = RunnablePassthrough.assign(\n",
        "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        ") | prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3865c2c-cb80-4341-bcbe-3b5150749622",
      "metadata": {
        "height": 62,
        "id": "a3865c2c-cb80-4341-bcbe-3b5150749622"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b036fc-446f-4075-9a92-9a4bac6ecb2b",
      "metadata": {
        "height": 45,
        "id": "40b036fc-446f-4075-9a92-9a4bac6ecb2b"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect agent_executor object\n",
        "agent_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI9s91XUtNxY",
        "outputId": "4884dfa5-5786-46ba-a0ad-54785c4e51e0"
      },
      "id": "qI9s91XUtNxY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(memory=ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?', additional_kwargs={}, response_metadata={}), HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current temperature in San Francisco is 13.6°C. Is there anything else you would like to know?', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='my name is George', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, George! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"what's the weather in SF?\", additional_kwargs={}, response_metadata={}), AIMessage(content='The current temperature in San Francisco is 13.6°C. Is there anything else you would like to know, George?', additional_kwargs={}, response_metadata={})]), return_messages=True, memory_key='chat_history'), verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_functions(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7c4667bfede0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7c4667bfede0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are helpful but sassy assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
              "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7c4667dd11f0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7c46744d5940>, root_client=<openai.OpenAI object at 0x7c4586134380>, root_async_client=<openai.AsyncOpenAI object at 0x7c4585a32ab0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), kwargs={'functions': [{'name': 'get_current_temperature', 'description': 'Fetch current temperature for given coordinates.', 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for', 'type': 'number'}, 'longitude': {'description': 'Longitude of the location to fetch weather data for', 'type': 'number'}}, 'required': ['latitude', 'longitude'], 'type': 'object'}}, {'name': 'search_wikipedia', 'description': 'Run Wikipedia search and get page summaries.', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}]}, config={}, config_factories=[])\n",
              "| OpenAIFunctionsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='get_current_temperature', description='Fetch current temperature for given coordinates.', args_schema=<class '__main__.OpenMeteoInput'>, func=<function get_current_temperature at 0x7c45859ea2a0>), StructuredTool(name='search_wikipedia', description='Run Wikipedia search and get page summaries.', args_schema=<class 'langchain_core.utils.pydantic.search_wikipedia'>, func=<function search_wikipedia at 0x7c4585af0fe0>)])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f70acf-57ff-4ab9-a942-f0ad6e680c40",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37f70acf-57ff-4ab9-a942-f0ad6e680c40",
        "outputId": "1ff77c24-afed-4cec-848d-b5d6552b8a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'my name is bob',\n",
              " 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"my name is bob\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1554b0c-8c72-4d8d-bbed-20afd94828c5",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1554b0c-8c72-4d8d-bbed-20afd94828c5",
        "outputId": "9cf74118-e3d9-494d-bb28-309a45543aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYou just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'whats my name',\n",
              " 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?'}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"whats my name\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40887f61-6746-4e51-852d-5ff0457384b7",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40887f61-6746-4e51-852d-5ff0457384b7",
        "outputId": "8864f14f-2412-446c-c5bb-f006de3448d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mThe current temperature is 13.6°C\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in San Francisco is 13.6°C. Is there anything else you would like to know?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'whats the weather in sf?',\n",
              " 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The current temperature in San Francisco is 13.6°C. Is there anything else you would like to know?', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'The current temperature in San Francisco is 13.6°C. Is there anything else you would like to know?'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we built a simple agent step by step. First, we defined a function to run the agent (```run_agent```) by keeping track of intermediate steps: the model decides which tool to call, we execute the tool, and store the observations. Next, we wrapped this workflow using RunnablePassthrough to create a chain (```agent_chain```) that handles the agent scratchpad and passes it to the model. We then set up a prompt using ChatPromptTemplate with placeholders for chat history and intermediate steps, connected it to the model and an output parser, and finally combined everything into an ```AgentExecutor```. To make the agent conversational, we added ```ConversationBufferMemory``` so it remembers the chat history, and then invoked it with a user input, letting the agent call the appropriate tools and respond intelligently."
      ],
      "metadata": {
        "id": "9Udjn5W4pt5B"
      },
      "id": "9Udjn5W4pt5B"
    },
    {
      "cell_type": "markdown",
      "id": "34b0b511-21d6-4c7e-b4e2-f886bc296997",
      "metadata": {
        "id": "34b0b511-21d6-4c7e-b4e2-f886bc296997"
      },
      "source": [
        "## Create a chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's integrate the agent into a chatbot setup to make the interaction more realistic and conversational."
      ],
      "metadata": {
        "id": "RJ0tMSUIqfw3"
      },
      "id": "RJ0tMSUIqfw3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1cd4bd2-703e-4e4e-8f5c-ae3d491a41f6",
      "metadata": {
        "height": 113,
        "id": "b1cd4bd2-703e-4e4e-8f5c-ae3d491a41f6"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def create_your_own(query: str) -> str:\n",
        "    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n",
        "    print(type(query))\n",
        "    return query[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cb6fdc-ff55-4a7b-8a39-1871006aa990",
      "metadata": {
        "height": 45,
        "id": "67cb6fdc-ff55-4a7b-8a39-1871006aa990"
      },
      "outputs": [],
      "source": [
        "tools = [get_current_temperature, search_wikipedia, create_your_own]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a73e69-acfb-471e-b54d-8ac586235521",
      "metadata": {
        "height": 708,
        "id": "66a73e69-acfb-471e-b54d-8ac586235521"
      },
      "outputs": [],
      "source": [
        "# import panel as pn  # GUI\n",
        "# pn.extension()\n",
        "# import param\n",
        "\n",
        "# class cbfs(param.Parameterized):\n",
        "\n",
        "#     def __init__(self, tools, **params):\n",
        "#         super(cbfs, self).__init__( **params)\n",
        "#         self.panels = []\n",
        "#         self.functions = [convert_to_openai_function(f) for f in tools]\n",
        "#         self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)\n",
        "#         self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
        "#         self.prompt = ChatPromptTemplate.from_messages([\n",
        "#             (\"system\", \"You are helpful but sassy assistant\"),\n",
        "#             MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "#             (\"user\", \"{input}\"),\n",
        "#             MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "#         ])\n",
        "#         self.chain = RunnablePassthrough.assign(\n",
        "#             agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        "#         ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
        "#         self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
        "\n",
        "#     def convchain(self, query):\n",
        "#         if not query:\n",
        "#             return\n",
        "#         inp.value = ''\n",
        "#         result = self.qa.invoke({\"input\": query})\n",
        "#         self.answer = result['output']\n",
        "#         self.panels.extend([\n",
        "#             pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
        "#             pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
        "#         ])\n",
        "#         return pn.WidgetBox(*self.panels, scroll=True)\n",
        "\n",
        "\n",
        "#     def clr_history(self,count=0):\n",
        "#         self.chat_history = []\n",
        "#         return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080c3827-87fc-4dbe-a566-ca95b3f9068e",
      "metadata": {
        "height": 334,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "080c3827-87fc-4dbe-a566-ca95b3f9068e",
        "outputId": "2d956b10-fc82-4d6d-b4a8-96820c653b49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div id='6253ecd2-9084-45e8-b868-572e5c31305a'>\n",
              "  <div id=\"f7340cd1-6f90-4b2f-8e46-31e5e6ccb60e\" data-root-id=\"6253ecd2-9084-45e8-b868-572e5c31305a\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"0c26e186-2154-470c-a375-b665415b22d9\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.layout.Column\",\"id\":\"6253ecd2-9084-45e8-b868-572e5c31305a\",\"attributes\":{\"name\":\"Column00136\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"114c3a9e-f904-449c-acc1-b955f00682bc\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/theme/default.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"6b3f8359-18ee-49d8-a914-f2c971161ffa\",\"attributes\":{\"name\":\"Row00134\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"114c3a9e-f904-449c-acc1-b955f00682bc\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"13844a84-7e89-4386-aef9-2b504a59e7c0\",\"attributes\":{\"css_classes\":[\"markdown\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"a540ffcc-f9b3-4a0d-a4a7-09352d73e3d3\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/markdown.css\"}},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;h1 id=&quot;qna_bot&quot;&gt;QnA_Bot &lt;a class=&quot;header-anchor&quot; href=&quot;#qna_bot&quot;&gt;\\u00b6&lt;/a&gt;&lt;/h1&gt;\\n\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.tabs.Tabs\",\"id\":\"63464ef4-4808-4a98-9ae6-1d2d40d5d812\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"margin\":0,\"align\":\"start\",\"tabs\":[{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"39a4659b-e854-4ceb-9d5d-d1cada0a7731\",\"attributes\":{\"name\":\"Column00131\",\"title\":\"Conversation\",\"child\":{\"type\":\"object\",\"name\":\"panel.models.layout.Column\",\"id\":\"9c1f7b5b-dba0-4bd1-ab42-b2260633638e\",\"attributes\":{\"name\":\"Column00131\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"114c3a9e-f904-449c-acc1-b955f00682bc\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"77f6cfb7-f843-4710-9923-3b98ab95ee2c\",\"attributes\":{\"name\":\"Row00122\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"114c3a9e-f904-449c-acc1-b955f00682bc\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.widgets.TextInput\",\"id\":\"02f77e2c-182a-4cd1-8e0a-6ac707a6dd95\",\"attributes\":{\"js_property_callbacks\":{\"type\":\"map\",\"entries\":[[\"change:value\",[{\"type\":\"object\",\"name\":\"CustomJS\",\"id\":\"08c41685-fe51-4977-a5cd-ec9d19c6f5b3\",\"attributes\":{\"tags\":[[136638036639872,[null,\"value\"],[null,\"loading\"]]],\"args\":{\"type\":\"map\",\"entries\":[[\"bidirectional\",false],[\"properties\",{\"type\":\"map\",\"entries\":[[\"value\",\"loading\"]]}],[\"source\",{\"id\":\"02f77e2c-182a-4cd1-8e0a-6ac707a6dd95\"}],[\"target\",{\"type\":\"object\",\"name\":\"panel.models.layout.Column\",\"id\":\"c771c3ce-ac5f-40cc-b2ac-e827d42fa215\",\"attributes\":{\"name\":\"Column00128\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"114c3a9e-f904-449c-acc1-b955f00682bc\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"height\":400,\"min_height\":400,\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"0ad2b707-83a0-4cf8-8c9b-1d9d44e40f81\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt; &lt;/pre&gt;\"}}]}}]]},\"code\":\"\\n    if ('value'.startsWith('event:')) {\\n      var value = true\\n    } else {\\n      var value = source['value'];\\n      value = value;\\n    }\\n    if (typeof value !== 'boolean' || source.labels !== ['Loading']) {\\n      value = true\\n    }\\n    var css_classes = target.css_classes.slice()\\n    var loading_css = ['pn-loading', 'pn-arc']\\n    if (value) {\\n      for (var css of loading_css) {\\n        if (!(css in css_classes)) {\\n          css_classes.push(css)\\n        }\\n      }\\n    } else {\\n     for (var css of loading_css) {\\n        var index = css_classes.indexOf(css)\\n        if (index > -1) {\\n          css_classes.splice(index, 1)\\n        }\\n      }\\n    }\\n    target['css_classes'] = css_classes\\n    \"}}]]]},\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"enter-pressed\"]},\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"id\":\"020ac926-d591-48f2-a9d8-757d5695a657\"},{\"id\":\"b87f8c7c-0621-4e59-b010-7554f204cb6c\"},{\"id\":\"7de72d9e-7197-4238-8349-d9e32b4d2446\"}],\"width\":300,\"min_width\":300,\"margin\":[5,10],\"align\":\"start\",\"placeholder\":\"Enter text here\\u2026\",\"max_length\":5000}}]}},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"9fe18be1-687c-4918-898e-62ff0753c630\",\"attributes\":{\"name\":\"Divider00123\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"9618e45d-80b6-4bdb-96c0-79709aad852e\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"6a52b48d-4555-49df-be21-70b993e0e85f\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}},{\"id\":\"c771c3ce-ac5f-40cc-b2ac-e827d42fa215\"},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"7210f80b-e52d-4673-addb-5fec13901beb\",\"attributes\":{\"name\":\"Divider00130\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 300px));\\n  -webkit-mask-size: auto calc(min(50%, 300px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"999f2c24-8950-4d38-b363-d680b9c73022\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"4c9bd475-ffeb-4630-8bb5-16a2e11f35d2\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.8.3/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}}]}}}}]}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"81dd739e-7666-46ca-b155-ba6b2bf9937a\",\"attributes\":{\"plot_id\":\"6253ecd2-9084-45e8-b868-572e5c31305a\",\"comm_id\":\"736b9f3fd31a40e087bda47b1741fa25\",\"client_comm_id\":\"edaa0383a1ab46dbbd3b2f85785a00df\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"0c26e186-2154-470c-a375-b665415b22d9\",\"roots\":{\"6253ecd2-9084-45e8-b868-572e5c31305a\":\"f7340cd1-6f90-4b2f-8e46-31e5e6ccb60e\"},\"root_ids\":[\"6253ecd2-9084-45e8-b868-572e5c31305a\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ],
            "application/vnd.holoviews_exec.v0+json": "",
            "text/plain": [
              "Column\n",
              "    [0] Row\n",
              "        [0] Markdown(str)\n",
              "    [1] Tabs\n",
              "        [0] Column\n",
              "            [0] Row\n",
              "                [0] TextInput(placeholder='Enter text here…')\n",
              "            [1] Divider()\n",
              "            [2] ParamFunction(function, _pane=Str, defer_load=False, height=400, loading_indicator=True)\n",
              "            [3] Divider()"
            ]
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "6253ecd2-9084-45e8-b868-572e5c31305a"
            }
          },
          "execution_count": 78
        }
      ],
      "source": [
        "# cb = cbfs(tools)\n",
        "\n",
        "# inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
        "\n",
        "# conversation = pn.bind(cb.convchain, inp)\n",
        "\n",
        "# tab1 = pn.Column(\n",
        "#     pn.Row(inp),\n",
        "#     pn.layout.Divider(),\n",
        "#     pn.panel(conversation,  loading_indicator=True, height=400),\n",
        "#     pn.layout.Divider(),\n",
        "# )\n",
        "\n",
        "# dashboard = pn.Column(\n",
        "#     pn.Row(pn.pane.Markdown('# QnA_Bot')),\n",
        "#     pn.Tabs(('Conversation', tab1))\n",
        "# )\n",
        "# dashboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat(query, history=[]):\n",
        "    if not query:\n",
        "        return history\n",
        "    result = agent_executor.invoke({\"input\": query})\n",
        "\n",
        "    # AgentExecutor returns AIMessage objects, extract text\n",
        "    if hasattr(result, 'get') and 'output' in result:\n",
        "        answer = result['output']\n",
        "    elif hasattr(result, 'output_text'):\n",
        "        answer = result.output_text\n",
        "    else:\n",
        "        # fallback: try memory\n",
        "        answer = str(result)\n",
        "\n",
        "    history.append((query, answer))\n",
        "    return history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(placeholder=\"Enter message...\")\n",
        "    msg.submit(chat, [msg, chatbot], chatbot)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "BCjpEGBWsCgh",
        "outputId": "2ccdf0cf-b9e1-4d40-bbbd-43b2934f6eb7"
      },
      "id": "BCjpEGBWsCgh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3612071819.py:21: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2643cf8252cfdc4a38.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2643cf8252cfdc4a38.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we first defined tools as we explored analytically in the previous session (notebook), then explicitly created an agent to use them, and finally set up a chatbot powered by this agent to enable real, interactive conversations."
      ],
      "metadata": {
        "id": "B3CEV12Lrhkv"
      },
      "id": "B3CEV12Lrhkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41804e2f-4dc1-4763-8893-5e76ab5d8f14",
      "metadata": {
        "height": 30,
        "id": "41804e2f-4dc1-4763-8893-5e76ab5d8f14"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}