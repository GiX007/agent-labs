{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX007/agent-labs/blob/main/03_langchain/06_openai_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3df44d6-62d0-4324-8052-419503a6b040",
      "metadata": {
        "id": "a3df44d6-62d0-4324-8052-419503a6b040"
      },
      "source": [
        "# OpenAI Function Calling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "BZu-2Lm4S8Lf"
      },
      "id": "BZu-2Lm4S8Lf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "dotenv_path = find_dotenv() or '/content/OPENAI_API_KEY.env' # read local .env file\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "client = openai.OpenAI(api_key=openai_api_key)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling"
      ],
      "metadata": {
        "id": "nRRdOLrzS9_B"
      },
      "id": "nRRdOLrzS9_B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
      "metadata": {
        "height": 249,
        "id": "e036b435-e842-40a3-8e1c-1d5d716394c6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
      "metadata": {
        "height": 334,
        "id": "290fae11-d9af-40f8-9b78-3d6a847737b2"
      },
      "outputs": [],
      "source": [
        "# Define a list of dicts so the model knows what functions it can call and their argument schema\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather in a given location\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                },\n",
        "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pass a message that is related to a function"
      ],
      "metadata": {
        "id": "2VQKFCWrZ4oY"
      },
      "id": "2VQKFCWrZ4oY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
      "metadata": {
        "height": 115,
        "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What's the weather like in Boston?\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46",
      "metadata": {
        "height": 147,
        "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46"
      },
      "outputs": [],
      "source": [
        "# Call the ChatCompletion endpoint\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e341605-5e3e-44d1-b64e-79c121aeb8d8",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e341605-5e3e-44d1-b64e-79c121aeb8d8",
        "outputId": "8ef39414-82b8-4e93-aecb-feb0353723d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbN14eLwML8j8atO6S6mer5afFasP', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), tool_calls=None))], created=1763022646, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=17, prompt_tokens=79, total_tokens=96, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3",
      "metadata": {
        "height": 30,
        "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3"
      },
      "outputs": [],
      "source": [
        "response_message = response.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7f733bd-e75b-4a84-9cbe-1a8c695015a3",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f733bd-e75b-4a84-9cbe-1a8c695015a3",
        "outputId": "8898fbdf-0e3f-4398-b0d3-2709d6979efd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "response_message"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = response.choices[0].message.content\n",
        "content # this is None as you see above"
      ],
      "metadata": {
        "id": "x1hQz6PBSLUE"
      },
      "id": "x1hQz6PBSLUE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d58d13f4-d131-4f70-8b68-dca7be2073e2",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d58d13f4-d131-4f70-8b68-dca7be2073e2",
        "outputId": "7f0bee4a-baa3-40c8-e4a8-1facc2f71db7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "response_message.function_call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433a51b6-9c92-4765-85aa-285dccf7748b",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "433a51b6-9c92-4765-85aa-285dccf7748b",
        "outputId": "635a5372-aac2-47d4-e6cb-05ce3bf8414e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'location': 'Boston, MA'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "json.loads(response_message.function_call.arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675d9372-4388-4f18-b44c-e291668ea46d",
      "metadata": {
        "height": 45,
        "id": "675d9372-4388-4f18-b44c-e291668ea46d"
      },
      "outputs": [],
      "source": [
        "args = json.loads(response_message.function_call.arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
        "outputId": "8b35cd47-0d00-4812-fbf1-684572fc1843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"location\": {\"location\": \"Boston, MA\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "get_current_weather(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model correctly understood that it should use the function instead of generating its own answer, and it also correctly produced the required arguments. By passing these arguments to the function locally, we execute it and obtain the actual result."
      ],
      "metadata": {
        "id": "itrDCwguW4pj"
      },
      "id": "itrDCwguW4pj"
    },
    {
      "cell_type": "markdown",
      "id": "3774d311",
      "metadata": {
        "id": "3774d311"
      },
      "source": [
        "### Pass a message that is not related to a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8",
      "metadata": {
        "height": 115,
        "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"hi!\",\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8300232d-4f02-478b-bba2-d47173422866",
      "metadata": {
        "height": 130,
        "id": "8300232d-4f02-478b-bba2-d47173422866"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e35564e-8f66-4b06-b14a-03e24a202a47",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e35564e-8f66-4b06-b14a-03e24a202a47",
        "outputId": "074b2009-314b-4d0b-ee71-cdd4c05da44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbN7xRi7QGcTzIdcn5KYnYZlcSK02', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763023073, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=10, prompt_tokens=74, total_tokens=84, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice what the model answers and also that it understands not to use the function."
      ],
      "metadata": {
        "id": "REAT9qFFXu-z"
      },
      "id": "REAT9qFFXu-z"
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8F6iOgmXZXX",
        "outputId": "3a512a0d-f9a9-48c1-a239-8b33afbbd122"
      },
      "id": "f8F6iOgmXZXX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nMDq6rtXl5f",
        "outputId": "c569694f-3afe-4205-d057-ed2ec52dd80e"
      },
      "id": "4nMDq6rtXl5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af7aae46",
      "metadata": {
        "id": "af7aae46"
      },
      "source": [
        "### Pass additional parameters to force the model to use or not a function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2af9f72-1cb9-4a97-b030-22562ecab99d",
      "metadata": {
        "height": 266,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2af9f72-1cb9-4a97-b030-22562ecab99d",
        "outputId": "0d708c88-036a-483d-d2dc-3161b165b0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbND72qXkDSoIvtD6VygzCWc1fyL9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763023393, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=10, prompt_tokens=74, total_tokens=84, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"hi!\",\n",
        "    }\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=\"auto\", # llm chooses in this case\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd2cNZUTYjeK",
        "outputId": "e5904230-d99b-4537-f394-0fb6603de870"
      },
      "id": "Hd2cNZUTYjeK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itgpQJjHYjau",
        "outputId": "1e8c3b7f-30ca-4130-9b9e-99fe698b4579"
      },
      "id": "itgpQJjHYjau",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting ```function_call=\"auto\"``` explicitly lets the model decide whether to call a function or respond with text. In messages like ```\"hi!\"```, the model correctly responds directly, but for requests that match a function's purpose, it will produce a function_call automatically."
      ],
      "metadata": {
        "id": "n2zW2AZdYnbm"
      },
      "id": "n2zW2AZdYnbm"
    },
    {
      "cell_type": "markdown",
      "id": "284088e9",
      "metadata": {
        "id": "284088e9"
      },
      "source": [
        "### Use mode 'none' for function call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba8cafc-f785-4595-9e3c-48b06424ee8b",
      "metadata": {
        "height": 266,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ba8cafc-f785-4595-9e3c-48b06424ee8b",
        "outputId": "9d1df4ef-b57f-45aa-fb56-6a0edf5a73dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbNF6AWdjaB8QDoi0oCAYlt4QNhgW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763023516, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=9, prompt_tokens=75, total_tokens=84, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"hi!\",\n",
        "    }\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=\"none\",\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv98k9XlZFjm",
        "outputId": "2dd271a8-d02c-4a34-b69b-248105afa836"
      },
      "id": "Jv98k9XlZFjm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oitLVQ0EZJCc",
        "outputId": "e802936b-507b-468d-f886-3fdc9be55318"
      },
      "id": "oitLVQ0EZJCc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, setting function_call=\"none\" forces the model not to call any functions, no matter what the user asks. So even if the user’s message could match a function, the model will always respond with plain text."
      ],
      "metadata": {
        "id": "M8YZlToSZEo7"
      },
      "id": "M8YZlToSZEo7"
    },
    {
      "cell_type": "markdown",
      "id": "ae05a76e",
      "metadata": {
        "id": "ae05a76e"
      },
      "source": [
        "### When the message should call a function and still uses mode 'none'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7cc5a7-1572-4171-9016-9ec2871d389b",
      "metadata": {
        "height": 266,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca7cc5a7-1572-4171-9016-9ec2871d389b",
        "outputId": "90c063ec-62c9-42a7-dfad-812847aca195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbNGxjJGXEm1MpH0BojorbQIX1ggs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Please hold on a moment while I get the current weather for Boston.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763023631, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=14, prompt_tokens=79, total_tokens=93, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What's the weather in Boston?\",\n",
        "    }\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=\"none\",\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hocMsrW1ZTKN",
        "outputId": "0ddd1eac-48ec-47bd-e27e-04bc2da97895"
      },
      "id": "hocMsrW1ZTKN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please hold on a moment while I get the current weather for Boston.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yisQbmcZTxL",
        "outputId": "c8506769-ca51-42b9-f661-ffaa7cb23c85"
      },
      "id": "9yisQbmcZTxL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38735d9f",
      "metadata": {
        "id": "38735d9f"
      },
      "source": [
        "### Force calling a function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282a92ba-5677-4c72-b556-d29e6a4152a0",
      "metadata": {
        "height": 266,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "282a92ba-5677-4c72-b556-d29e6a4152a0",
        "outputId": "55647b17-11ab-4a9b-f7a8-636ccdb5076f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbNHUt6RCv8gzV9HofmcZD00UsufA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"New York, NY\"}', name='get_current_weather'), tool_calls=None))], created=1763023664, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=8, prompt_tokens=84, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"hi!\",\n",
        "    }\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call={\"name\": \"get_current_weather\"},\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRMfeRjpZj-3",
        "outputId": "3e164e8f-7456-4cba-a0a4-c0e43bdc04d1"
      },
      "id": "wRMfeRjpZj-3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-vtv3yVZoEI",
        "outputId": "0eaf24be-44d9-4589-9509-0756f7f378d6"
      },
      "id": "F-vtv3yVZoEI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FunctionCall(arguments='{\"location\":\"New York, NY\"}', name='get_current_weather')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27abbdc",
      "metadata": {
        "id": "b27abbdc"
      },
      "source": [
        "### Final notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5229a4-2700-48b4-b2b9-3b1e1535f903",
      "metadata": {
        "height": 266,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c5229a4-2700-48b4-b2b9-3b1e1535f903",
        "outputId": "0ce8ce09-23f7-4cf3-d14e-0e9f35568118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbNMPYw845VtGyxVPsRHIfQyde0Hk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), tool_calls=None))], created=1763023969, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=7, prompt_tokens=89, total_tokens=96, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What's the weather like in Boston!\",\n",
        "    }\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call={\"name\": \"get_current_weather\"},\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2I0uQ8Eau99",
        "outputId": "bae07a12-473a-4a84-fa7a-fa8a2b915f83"
      },
      "id": "i2I0uQ8Eau99",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6qq7eToayKn",
        "outputId": "ad53d975-c4ca-44c6-e73f-fb2aaf1cf1a1"
      },
      "id": "X6qq7eToayKn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c817376f-3a7f-4448-acdd-1639c70d42e4",
      "metadata": {
        "height": 62,
        "id": "c817376f-3a7f-4448-acdd-1639c70d42e4"
      },
      "outputs": [],
      "source": [
        "args = json.loads(response.choices[0].message.function_call.arguments)\n",
        "observation = get_current_weather(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ZC5jYHbfRi",
        "outputId": "5b476fe8-551c-4a79-bec5-55e8eea95e57"
      },
      "id": "N7ZC5jYHbfRi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"location\": {\"location\": \"Boston, MA\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63454808-10a2-4301-9977-89aa79018152",
      "metadata": {
        "height": 132,
        "id": "63454808-10a2-4301-9977-89aa79018152"
      },
      "outputs": [],
      "source": [
        "messages.append(\n",
        "        {\n",
        "            \"role\": \"function\",\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"content\": observation,\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f323fb69-c907-4f19-a2d9-80d828b4a5c2",
      "metadata": {
        "height": 98,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f323fb69-c907-4f19-a2d9-80d828b4a5c2",
        "outputId": "c265cdd6-6b7d-4f13-c759-1e8050393f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-CbNOc7KI9URV19R3T7zoSqFeQkEqI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The weather in Boston is currently 72°F, with sunny and windy conditions.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763024106, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=16, prompt_tokens=56, total_tokens=72, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuYDgmDobP_u",
        "outputId": "e70d719e-9fda-4875-c78e-d911eeb71e10"
      },
      "id": "XuYDgmDobP_u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Boston is currently 72°F, with sunny and windy conditions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we explored step by step how a model (LLM) determines when to use a function for different user prompts. In this implementation, we manually extracted the arguments generated by the model, passed them to the corresponding function, and then fed the function's output back to the LLM to produce the final natural-language answer.\n"
      ],
      "metadata": {
        "id": "DrFBKMs-blnL"
      },
      "id": "DrFBKMs-blnL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes**:\n",
        "- LLMs don't always produce the same results."
      ],
      "metadata": {
        "id": "8K_iNkpPaIpw"
      },
      "id": "8K_iNkpPaIpw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a2ba14-9908-48b1-adad-1ef764114254",
      "metadata": {
        "height": 30,
        "id": "37a2ba14-9908-48b1-adad-1ef764114254"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}