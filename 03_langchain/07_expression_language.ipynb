{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX007/agent-labs/blob/main/03_langchain/07_expression_language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc925562",
      "metadata": {
        "id": "fc925562"
      },
      "source": [
        "# LangChain Expression Language (LCEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "trCppFxqdI-7"
      },
      "id": "trCppFxqdI-7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "044db1b7-c18c-45d2-be7a-29f027c901e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "dotenv_path = find_dotenv() or '/content/OPENAI_API_KEY.env' # read local .env file\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "client = openai.OpenAI(api_key=openai_api_key)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de9d2bd-18de-44d5-81ac-5918e2106367",
      "metadata": {
        "height": 30,
        "id": "2de9d2bd-18de-44d5-81ac-5918e2106367"
      },
      "outputs": [],
      "source": [
        "#!pip install pydantic==1.10.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-community docarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0_9EQkEdd3D",
        "outputId": "c6a60f82-1e10-4c78-b7d5-7f43a76c4a33"
      },
      "id": "Y0_9EQkEdd3D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.35)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: docarray in /usr/local/lib/python3.12/dist-packages (0.41.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.12/dist-packages (from docarray) (3.11.4)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.12/dist-packages (from docarray) (13.9.4)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.12/dist-packages (from docarray) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from docarray) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.1.0->docarray) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.1.0->docarray) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->docarray) (1.1.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e",
      "metadata": {
        "height": 64,
        "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
      "metadata": {
        "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740"
      },
      "source": [
        "## Simple Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0be20d-0e00-478c-a844-017cad13af22",
      "metadata": {
        "height": 98,
        "id": "6a0be20d-0e00-478c-a844-017cad13af22"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"tell me a short joke about {topic}\"\n",
        ")\n",
        "model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
      "metadata": {
        "height": 30,
        "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
        "outputId": "c418ee80-79d8-42c6-946f-7559f31ea9d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the bear bring a flashlight to the party? \\n\\nBecause he wanted to be the \"bright\"est one there!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
      "metadata": {
        "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a"
      },
      "source": [
        "## More complex chain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also use ```Runnable Map``` to supply user-provided inputs to the prompt."
      ],
      "metadata": {
        "id": "mLyvScmTebPy"
      },
      "id": "mLyvScmTebPy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
      "metadata": {
        "height": 47,
        "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
      "metadata": {
        "height": 113,
        "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702"
      },
      "outputs": [],
      "source": [
        "# Create an in-memory vector store from text documents using OpenAI embeddings, then get a retriever to perform similarity search\n",
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
        "    embedding=OpenAIEmbeddings()\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all methods and attributes\n",
        "print(dir(retriever))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZSeECLwfIIP",
        "outputId": "ceecf368-9603-46ad-93c7-67909ca02049"
      },
      "id": "VZSeECLwfIIP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['InputType', 'OutputType', '__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__orig_bases__', '__parameters__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__ror__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abatch_with_config', '_abc_impl', '_acall_with_config', '_aget_relevant_documents', '_atransform_stream_with_config', '_batch_with_config', '_calculate_keys', '_call_with_config', '_copy_and_set_values', '_expects_other_args', '_get_ls_params', '_get_relevant_documents', '_get_value', '_iter', '_new_arg_supported', '_setattr_handler', '_transform_stream_with_config', 'aadd_documents', 'abatch', 'abatch_as_completed', 'add_documents', 'aget_relevant_documents', 'ainvoke', 'allowed_search_types', 'as_tool', 'assign', 'astream', 'astream_events', 'astream_log', 'atransform', 'batch', 'batch_as_completed', 'bind', 'config_schema', 'config_specs', 'configurable_alternatives', 'configurable_fields', 'construct', 'copy', 'dict', 'from_orm', 'get_config_jsonschema', 'get_graph', 'get_input_jsonschema', 'get_input_schema', 'get_lc_namespace', 'get_name', 'get_output_jsonschema', 'get_output_schema', 'get_prompts', 'get_relevant_documents', 'input_schema', 'invoke', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'map', 'metadata', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'name', 'output_schema', 'parse_file', 'parse_obj', 'parse_raw', 'pick', 'pipe', 'schema', 'schema_json', 'search_kwargs', 'search_type', 'stream', 'tags', 'to_json', 'to_json_not_implemented', 'transform', 'update_forward_refs', 'validate', 'validate_search_type', 'vectorstore', 'with_alisteners', 'with_config', 'with_fallbacks', 'with_listeners', 'with_retry', 'with_types']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print only “public” retriever methods\n",
        "methods = [\n",
        "    m for m in dir(retriever)\n",
        "    if callable(getattr(retriever, m, None)) # callable\n",
        "    and not m.startswith(\"_\") # ignore private/internal\n",
        "]\n",
        "print(methods)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rop3Kyjfrbw",
        "outputId": "715bcd73-862f-4150-c5b2-b0fac336abdc"
      },
      "id": "2Rop3Kyjfrbw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['InputType', 'OutputType', 'aadd_documents', 'abatch', 'abatch_as_completed', 'add_documents', 'aget_relevant_documents', 'ainvoke', 'as_tool', 'assign', 'astream', 'astream_events', 'astream_log', 'atransform', 'batch', 'batch_as_completed', 'bind', 'config_schema', 'configurable_alternatives', 'configurable_fields', 'construct', 'copy', 'dict', 'from_orm', 'get_config_jsonschema', 'get_graph', 'get_input_jsonschema', 'get_input_schema', 'get_lc_namespace', 'get_name', 'get_output_jsonschema', 'get_output_schema', 'get_prompts', 'get_relevant_documents', 'input_schema', 'invoke', 'is_lc_serializable', 'json', 'lc_id', 'map', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_schema', 'parse_file', 'parse_obj', 'parse_raw', 'pick', 'pipe', 'schema', 'schema_json', 'stream', 'to_json', 'to_json_not_implemented', 'transform', 'update_forward_refs', 'validate', 'validate_search_type', 'with_alisteners', 'with_config', 'with_fallbacks', 'with_listeners', 'with_retry', 'with_types']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Retriever Methods**\n",
        "\n",
        "- `invoke`(~ `get_relevant_documents(query)`) → Retrieves documents from the retriever that are most relevant to the given query.    \n",
        "- `add_documents(documents)` → Adds new documents to the underlying vector store for future retrieval.  \n",
        "- `as_tool()` → Wraps the retriever as a LangChain tool so it can be used by agents."
      ],
      "metadata": {
        "id": "NoHBWODpgn6a"
      },
      "id": "NoHBWODpgn6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df87934-1697-405c-b460-5e9bfd16c792",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2df87934-1697-405c-b460-5e9bfd16c792",
        "outputId": "826cb154-7986-4718-c457-a4a26824540f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
              " Document(metadata={}, page_content='bears like to eat honey')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "retriever.invoke(\"where did harrison work?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
        "outputId": "bb7cf01b-90b1-48bf-8434-6e9a38f7e008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='bears like to eat honey'),\n",
              " Document(metadata={}, page_content='harrison worked at kensho')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "retriever.invoke(\"what do bears like to eat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
      "metadata": {
        "height": 130,
        "id": "127a7fb6-5821-4934-ab56-9e3300516c05"
      },
      "outputs": [],
      "source": [
        "# create a prompt template\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
      "metadata": {
        "height": 30,
        "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnableMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
      "metadata": {
        "height": 96,
        "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc"
      },
      "outputs": [],
      "source": [
        "chain = RunnableMap({\n",
        "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "}) | prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This defines a pipeline (RunnableMap) that takes an input dict with a \"question\":\n",
        " 1. \"context\" key: uses the retriever to get relevant documents for the question.\n",
        " 2. \"question\" key: just passes the original question through.\n",
        " Then the outputs are fed sequentially through:\n",
        " - `prompt` to format the input for the LLM,\n",
        " - `model` to generate a response,\n",
        " - `output_parser` to parse the LLM's output.\n",
        "\n",
        "In short: it retrieves relevant context, combines it with the question (chain), and produces (by the model) a processed answer.\n"
      ],
      "metadata": {
        "id": "6c1yytPgiOXq"
      },
      "id": "6c1yytPgiOXq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
        "outputId": "44c6f4ff-16ab-43e1-8f9e-5e213eff1a0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harrison worked at Kensho.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"where did harrison work?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ec3727-4284-417e-9e23-eec0682eb002",
      "metadata": {
        "height": 96,
        "id": "05ec3727-4284-417e-9e23-eec0682eb002"
      },
      "outputs": [],
      "source": [
        "# display RunnableMap's output\n",
        "inputs = RunnableMap({\n",
        "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
        "outputId": "b765d4e2-588b-4564-c51a-85481606d8a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
              "  Document(metadata={}, page_content='bears like to eat honey')],\n",
              " 'question': 'where did harrison work?'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "inputs.invoke({\"question\": \"where did harrison work?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
      "metadata": {
        "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863"
      },
      "source": [
        "## Bind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
      "metadata": {
        "height": 300,
        "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "      \"name\": \"weather_search\",\n",
        "      \"description\": \"Search for weather given an airport code\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"airport_code\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The airport code to get the weather for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "      }\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
      "metadata": {
        "height": 115,
        "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
      "metadata": {
        "height": 30,
        "id": "e61b095d-9934-41b8-a794-a9dd57e9c733"
      },
      "outputs": [],
      "source": [
        "runnable = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
        "outputId": "a79d1df9-67bf-4877-9537-face0bd777d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 64, 'total_tokens': 80, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbO9gajKCzMBjE8tU4grndghaPtZq', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--d2da2426-679d-4509-ae62-ae79ac4b9b07-0', usage_metadata={'input_tokens': 64, 'output_tokens': 16, 'total_tokens': 80, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "runnable.invoke({\"input\": \"what is the weather in sf\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a22faf5-ea24-48d2-b028-03733b548225",
      "metadata": {
        "height": 538,
        "id": "3a22faf5-ea24-48d2-b028-03733b548225"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "      \"name\": \"weather_search\",\n",
        "      \"description\": \"Search for weather given an airport code\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"airport_code\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The airport code to get the weather for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "      }\n",
        "    },\n",
        "        {\n",
        "      \"name\": \"sports_search\",\n",
        "      \"description\": \"Search for news of recent sport events\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"team_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The sports team to search for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"team_name\"]\n",
        "      }\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef",
      "metadata": {
        "height": 30,
        "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef"
      },
      "outputs": [],
      "source": [
        "model = model.bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567",
      "metadata": {
        "height": 30,
        "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567"
      },
      "outputs": [],
      "source": [
        "runnable = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
      "metadata": {
        "height": 45,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
        "outputId": "cbadd3a8-fff0-46b2-8686-1428543f3965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"New England Patriots\"}', 'name': 'sports_search'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 99, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CbOFNr62vY6KZoxXSCMPYqgEvpAGN', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--00855c95-d620-4d89-b97e-4fbe1687bcc8-0', usage_metadata={'input_tokens': 99, 'output_tokens': 18, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we use ```bind``` to pre-configure the LLM with additional context. In our case, the list of available functions. By binding the functions to the model, we create a version of the model that automatically “knows” which functions it can call whenever it is invoked, without needing to pass the functions each time. This is different from invoke, which actually runs the model on a specific input; bind simply sets up the model with persistent configuration, making it easier to integrate into pipelines or Runnables where the same context needs to be reused across multiple calls."
      ],
      "metadata": {
        "id": "_dCCWoZNnwst"
      },
      "id": "_dCCWoZNnwst"
    },
    {
      "cell_type": "markdown",
      "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
      "metadata": {
        "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a"
      },
      "source": [
        "## Fallbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
      "metadata": {
        "height": 47,
        "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
      "metadata": {
        "height": 115,
        "id": "df432efe-9415-42e3-ab57-ecf4d439f369"
      },
      "outputs": [],
      "source": [
        "simple_model = OpenAI(\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "simple_chain = simple_model | json.loads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
      "metadata": {
        "height": 45,
        "id": "441928c5-8712-45c5-bfdf-6f51634198a7"
      },
      "outputs": [],
      "source": [
        "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0739e85f-8497-4471-8ec9-17e958d80771",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0739e85f-8497-4471-8ec9-17e958d80771",
        "outputId": "013f00a1-e1c5-4ffa-fcd5-5afdc410d92d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'. \\n\\n```json\\n{\\n  \"poems\": [\\n    {\\n      \"title\": \"The Road Not Taken\",\\n      \"author\": \"Robert Frost\",\\n      \"first_line\": \"Two roads diverged in a yellow wood,\"\\n    },\\n    {\\n      \"title\": \"Still I Rise\",\\n      \"author\": \"Maya Angelou\",\\n      \"first_line\": \"You may write me down in history\"\\n    },\\n    {\\n      \"title\": \"The Waste Land\",\\n      \"author\": \"T.S. Eliot\",\\n      \"first_line\": \"April is the cruellest month,\"\\n    }\\n  ]\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "simple_model.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
      "metadata": {
        "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219"
      },
      "source": [
        "<p style=\\\"background-color:#F5C780; padding:15px\\\"><b>Note:</b> The next line is expected to fail.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5e8492-0927-4a3a-b939-947826246330",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "2a5e8492-0927-4a3a-b939-947826246330",
        "outputId": "32f8bf80-615e-4420-9d3b-bef153ddb698"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3924921287.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3244\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3245\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3246\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3247\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3248\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5023\u001b[0m         \"\"\"\n\u001b[1;32m   5024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5025\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   5026\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5027\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                 output = cast(\n\u001b[1;32m   2091\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2092\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   2093\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4880\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4882\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4883\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4884\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "source": [
        "simple_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
      "metadata": {
        "height": 47,
        "id": "6814143b-4a35-4d29-bd32-ba461274bcbf"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(temperature=0)\n",
        "chain = model | StrOutputParser() | json.loads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
        "outputId": "25967191-13d8-4b56-af00-d90172ad11f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'poem1': {'title': 'The Rose',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
              " 'poem2': {'title': 'The Road Not Taken',\n",
              "  'author': 'Robert Frost',\n",
              "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
              " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In LangChain, modern LLM classes like ```ChatOpenAI``` fully support the **Runnable interface**, so we can chain multiple steps (e.g., model → string parser → ```json.loads```) and call ```.invoke()``` on the whole chain. Deprecated classes like the old ```OpenAI``` do not, which is why similar chains fail.\n",
        "\n",
        "To address this, we can use **fallback chain**: if ```simple_chain``` fails or cannot handle the input, the call is automatically passed to ```chain``` as a backup. This ensures our pipeline can still produce a result even if the first chain encounters an error."
      ],
      "metadata": {
        "id": "y8yZLh9hrJFK"
      },
      "id": "y8yZLh9hrJFK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
      "metadata": {
        "height": 30,
        "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48"
      },
      "outputs": [],
      "source": [
        "final_chain = simple_chain.with_fallbacks([chain])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
        "outputId": "67a54222-433a-4950-9c25-64593d9357db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'poem1': {'title': 'The Rose',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
              " 'poem2': {'title': 'The Road Not Taken',\n",
              "  'author': 'Robert Frost',\n",
              "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
              " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "final_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
      "metadata": {
        "id": "3fcfdda0-3db2-4073-a647-f2d62c460349"
      },
      "source": [
        "## Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
      "metadata": {
        "height": 132,
        "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a short joke about {topic}\"\n",
        ")\n",
        "model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
        "outputId": "3278c671-e0df-452b-de33-c3dc4d9b51e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why do bears have hairy coats?\\n\\nFur protection!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
        "outputId": "63fc5b3c-0338-49b9-e319-9ecda82bf02b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Why do bears have hairy coats?\\n\\nFur protection!',\n",
              " 'Why are frogs so happy? Because they eat whatever bugs them!']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# batch lets us process multiple inputs in one call instead of invoking the chain separately for each item\n",
        "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
        "outputId": "61e46cb8-b9a6-470f-efb1-6c51e3da633a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Why\n",
            " do\n",
            " bears\n",
            " have\n",
            " hairy\n",
            " coats\n",
            "?\n",
            " \n",
            "\n",
            "F\n",
            "ur\n",
            " protection\n",
            "!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# chain.stream lets us receive the output incrementally as it’s generated instead of waiting for the entire chain to finish\n",
        "for t in chain.stream({\"topic\": \"bears\"}):\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
        "outputId": "7e86a077-bde7-4ff8-889d-2933262da8d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the bear bring a flashlight to the party? \\nHe heard it was going to be a \"beary\" good time!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# `ainvoke` runs the chain asynchronously, allowing other tasks to run while waiting, but still returns the final result only when the chain finishes\n",
        "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0",
      "metadata": {
        "height": 30,
        "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}